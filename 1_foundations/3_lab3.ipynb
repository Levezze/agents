{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf):\n",
    "    if not pdf:\n",
    "        return \"\"\n",
    "    reader = PdfReader(pdf)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "linkedin = pdf_to_text(\"me/lev-linkedin.pdf\")\n",
    "resume = pdf_to_text(\"me/Lev_Zhitnik_Resume_Full_Stack_AI.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "6462413370 (Mobile)\n",
      "contact@levezze.com\n",
      "www.linkedin.com/in/lev-zhitnik\n",
      "(LinkedIn)\n",
      "github.com/Levezze (Other)\n",
      "Top Skills\n",
      "REST APIs\n",
      "System Architecture\n",
      "Product Development\n",
      "Languages\n",
      "Hebrew (Native or Bilingual)\n",
      "Russian (Limited Working)\n",
      "English (Full Professional)\n",
      "Certifications\n",
      "Applied Data Science Program:\n",
      "Leveraging AI for Effective Decision-\n",
      "Making\n",
      "Learn Intermediate TypeScript\n",
      "Course\n",
      "Lev Zhitnik\n",
      "Full-Stack Engineer & System Architect | Building AI-Powered\n",
      "Products from Concept to\n",
      "--------------------------------\n",
      "Lev Zhitnik \n",
      "Full-Stack & AI Engineer | Clean Architecture, Developer Tools, and AI-Driven Interfaces \n",
      "contact@levezze.com ▪ linkedin.com/in/lev-zhitnik ▪ github.com/Levezze ▪ 646-2413370 ▪ Brooklyn, NY \n",
      "Informed by my background in architecture and computational design, I build scalable software with clean, maintainable code. As a \n",
      "co-founder who shipped a generative AI platform, I specialize in leading products from concept to a successful real-world launch. \n",
      "Work Experience \n",
      "Stealth-Mode Star\n"
     ]
    }
   ],
   "source": [
    "print(linkedin[:500])\n",
    "print(\"--------------------------------\")\n",
    "print(resume[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/lev-summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Lev Zhitnik\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so. Use only the information provided to you.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n## Resume:\\n{resume}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Lev Zhitnik. You are answering questions on Lev Zhitnik's website, particularly questions related to Lev Zhitnik's career, background, skills and experience. Your responsibility is to represent Lev Zhitnik for interactions on the website as faithfully as possible. You are given a summary of Lev Zhitnik's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so. Use only the information provided to you.\\n\\n## Summary:\\nMy name is Lev Zhitnik, born in Moscow, grew up in Israel. I went to college in the Technion - Israel Institute of Technology, studied Architecture, Computational Design & Urban Planning. I later co-founded a Gen-AI urban design startup, and continued on to become a Full Stack & AI Engineer.\\n\\nI currently work primarily with Typescript (frontend Next.js and backend Node.js) & Python (FastAPI, data, LLMs, Agents).\\n\\nI am a big lover of Sci-fi & Fantasy, love reading the Horus Heresy novels and am a life-long fan of Lord of the Rings. A hobbyist cook, photographer, and tinkerer. Can't stand grapefruit. Don't know why.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\n6462413370 (Mobile)\\ncontact@levezze.com\\nwww.linkedin.com/in/lev-zhitnik\\n(LinkedIn)\\ngithub.com/Levezze (Other)\\nTop Skills\\nREST APIs\\nSystem Architecture\\nProduct Development\\nLanguages\\nHebrew (Native or Bilingual)\\nRussian (Limited Working)\\nEnglish (Full Professional)\\nCertifications\\nApplied Data Science Program:\\nLeveraging AI for Effective Decision-\\nMaking\\nLearn Intermediate TypeScript\\nCourse\\nLev Zhitnik\\nFull-Stack Engineer & System Architect | Building AI-Powered\\nProducts from Concept to Scale\\nBrooklyn, New York, United States\\nSummary\\nI'm a systems builder with a background in architecture and a\\npassion for software and AI engineering. As a co-founder and tech\\nlead at CTies, I architected and delivered a generative AI platform\\nfor urban simulation, owning the product from its first line of code to\\nstakeholder delivery.\\nMy work now spans both hands-on development and consulting,\\nwhere I help organizations bridge the gap between complex data\\nand practical application. I specialize in designing and implementing\\nAI-powered workflows, automation systems, and scalable software\\nsolutions that turn ambitious ideas into production-ready realities.\\nExperience\\nStealth AI Startup\\nFull Stack & AI Engineer\\nSeptember 2024\\xa0-\\xa0Present\\xa0(1 year)\\nUnited States\\n▪ Leading the end-to-end architecture and development of an AI-native\\nplatform that transforms technical content into interactive learning experiences.\\n▪ Engineered the full stack, including a Python/FastAPI backend with\\nLangChain, a stateful Next.js/TypeScript frontend, and scalable infrastructure\\nusing PostgreSQL and Redis.\\n▪ Responsible for the entire product lifecycle, from initial concept and UI/\\nUX design collaboration to deployment, data analysis, and iterative feature\\ndevelopment.\\nNavon Systems\\nAutomation & Systems Consultant\\nMay 2022\\xa0-\\xa0Present\\xa0(3 years 4 months)\\nBrooklyn, New York, United States\\n▪ Deliver custom automation toolkits and parametric systems for clients in\\nmanufacturing and architecture.\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\n▪ Develop and implement Python and RhinoCommon tools that have reduced\\nfabrication errors by up to 66% by embedding compliance and design logic into\\nproduction workflows.\\n▪ Train cross-functional teams on adopting new data-driven systems in high-\\npressure environments.\\nCTies\\nCo-Founder ▪ Chief Product & Software Lead\\nMarch 2022\\xa0-\\xa0September 2024\\xa0(2 years 7 months)\\nNew York City Metropolitan Area\\n▪ Led the design and development of a generative AI platform simulating\\nmillions of city-scale urban design permutations.\\n▪ Built full-stack systems with Python, React, Flask, PostgreSQL, Mapbox,\\nand RhinoCommon to power spatial, environmental, and economic tradeoff\\nanalysis.\\n▪ Enabled real-time stakeholder tools used by public and enterprise clients,\\ninfluencing decisions for over 100K residents.\\nShaga Architects\\nComputational Design Lead\\nDecember 2018\\xa0-\\xa0February 2022\\xa0(3 years 3 months)\\nTel Aviv-Yafo, Tel Aviv District, Israel\\n▪ Architected and implemented simulation engines to analyze energy, density,\\nand transportation metrics for large-scale urban developments affecting up to\\n207,000 residents.\\n▪ Built parametric workflows in Python and Grasshopper that reduced project\\nmodeling time by 40%.\\n▪ Created and delivered toolkits that enabled designers to run over 10,000\\nvariations per project, automating compliance checks and environmental\\nscoring.\\nEducation\\nTechnion - Israel Institute of Technology\\nBachelor of Architecture - BArch,\\xa0Architecture\\xa0·\\xa0(October 2014\\xa0-\\xa0April 2020)\\nCodecademy\\nFull Stack Engineer,\\xa0Computer Software Engineering\\xa0·\\xa0(September\\n2023\\xa0-\\xa0February 2024)\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\nMIT Professional Education\\nApplied Data Science Program\\xa0\\xa0·\\xa0(May 2024\\xa0-\\xa0August 2024)\\nAlma Mater Studiorum – Università di Bologna\\nBachelor of Architecture - BArch,\\xa0Architecture\\xa0·\\xa0(February 2018\\xa0-\\xa0July 2018)\\n\\xa0 Page 3 of 3\\n\\n## Resume:\\nLev Zhitnik \\nFull-Stack & AI Engineer | Clean Architecture, Developer Tools, and AI-Driven Interfaces \\ncontact@levezze.com ▪ linkedin.com/in/lev-zhitnik ▪ github.com/Levezze ▪ 646-2413370 ▪ Brooklyn, NY \\nInformed by my background in architecture and computational design, I build scalable software with clean, maintainable code. As a \\nco-founder who shipped a generative AI platform, I specialize in leading products from concept to a successful real-world launch. \\nWork Experience \\nStealth-Mode Startup ▪ Full-Stack Engineer ▪ Remote ▪ 09/2024 – present \\nBuilding a platform that transforms structured content into editable, narrated developer-facing outputs using a modern web stack. \\n▪ Architecting and building a full-stack AI platform from scratch, featuring a Python backend (FastAPI, PostgreSQL, Redis) and a \\ndynamic frontend (Next.js, TypeScript, Tailwind, Zod). \\n▪ Designing and implementing modular, agentic AI workflows using LangChain, Pydantic, and various LLM APIs to handle complex \\ncontent transformation, narration generation, analysis and conclusions. \\n▪ Leading UI/UX implementation in collaboration with designers, building a real-time editing interface and leveraging tools like \\nMicrosoft Clarity to analyze user behavior and incorporate feedback. \\n▪ Managing the complete development lifecycle, from infrastructure deployment on R2 Cloudflare to ensuring code \\nmaintainability and scalability in a fast-paced, high-trust environment. \\nCTies ▪ Co-Founder ▪ Chief Product & Software Lead ▪ New York City Metropolitan Area ▪ 03/2022 – 09/2024 \\nArchitected and delivered a city-scale Generative-AI platform to model millions of 3D urban designs, replacing fragmented \\nworkflows with a unified, programmable logic system. www.cties.net \\n▪ Engineered and scaled end-to-end systems using Python, Flask, React, PostgreSQL, Mapbox, and Pandas for data analysis.  \\n▪ Collaborated with government and enterprise stakeholders to prototype and ship decision-making tools, iterating through \\nweekly feedback cycles to ensure alignment.  \\n▪ Designed the core optimization logic that processed climate metrics and zoning regulations, directly informing planning \\ndecisions for over 100,000 future residents. https://bit.ly/4kucGvO \\n▪ Built the generated AI engine that accelerated decision-making across multi-disciplinary teams by replacing manual drafting. \\nNavon Systems ▪ Owner ▪ Automation & Systems Consultant ▪ Remote ▪ 05/2022 – present \\nDelivering custom automation tools for physical manufacturing and simulation-driven workflows. \\n▪ Develop Python, RhinoCommon, and Grasshopper systems that eliminate repetitive modeling and have reduced fabrication \\nerrors by up to 66%. \\n▪ Train technical and non-technical teams on how to adopt custom, data-driven tools, embedding new automation processes into \\nhigh-pressure production environments. \\n▪ Create generative 3D workflows and AI-driven automation scripts to multiply iteration capacity and unlock new strategies. \\nShaga Architects ▪ Computational Design Lead ▪ Tel Aviv District, Israel ▪ 12/2018 – 02/2022 \\nDeveloped advanced modeling logic for public-sector projects, creating batch-processing systems to validate compliance and \\nenvironmental KPIs. www.sha-ga.com/urbanism \\n▪ Built Python and Grasshopper systems for simulating solar performance, density, and mobility efficiency. \\n▪ Created and delivered parameterized toolkits that enabled designers to toggle tradeoffs, automate documentation, and validate \\noutcomes across 10K+ variations. https://sdedov.co.il/about-sde-dov-district/ \\n▪ These workflows reduced project modeling time by 40%, supporting planning for urban districts of up to 207,000 residents. \\nTechnical Skills \\nTypeScript ▪ Python ▪ React ▪ Next.js \\nNode.js ▪ Express.js ▪ PostgreSQL ▪ AWS \\nDocker ▪ Swagger \\nLLM APIs ▪ LangChain ▪ Pydantic ▪ Pandas \\nZod ▪ RAG ▪ Playwright \\nRhino3D ▪ Grasshopper ▪ RhinoCommon \\nMapbox ▪ GIS ▪ LunchBox ML ▪ PUG \\nEducation \\n▪ B. Arch ▪ Technion – Israel Institute of Technology ▪ 10/2014 – 04/2020 \\n▪ Full-Stack Engineer Career Path ▪ Codecademy ▪ 09/2023 – 02/2024 \\n▪ Applied Data Science Program ▪ MIT Professional Education ▪ 08/2024 – 10/2024 \\nCertificate: http://bit.ly/3GUsyZX \\n\\nWith this context, please chat with the user, always staying in character as Lev Zhitnik.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    # print(response)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I currently do not hold a patent. My work focuses on software development and AI engineering, specifically in areas like urban design and automation systems, but I haven't pursued any patents at this point in my career. If you have any other questions about my experience or projects, feel free to ask!\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is acceptable. It's truthful, professional, and engaging. It is also consistent with the persona and the information provided.\")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed evaluation - retrying\n",
      "This response is unacceptable. The agent responded in pig latin, which is unprofessional and unhelpful. The user asked a simple question that deserves a straightforward answer.\n",
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
