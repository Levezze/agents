{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key exists and begins sk-\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you were tasked with designing an ethical framework for artificial intelligence that balances innovation with societal impact, what key principles would you prioritize, and how would you address potential conflicts between those principles?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing an ethical framework for artificial intelligence (AI) is a complex task that requires careful consideration of various principles to balance innovation with societal impact. Here are some key principles I would prioritize:\n",
       "\n",
       "1. **Transparency**: AI systems should be designed to be transparent in their decision-making processes. This includes providing clear explanations of how algorithms work and allowing stakeholders to understand how decisions are made.\n",
       "\n",
       "2. **Accountability**: There should be clear lines of responsibility for AI systems and their outcomes. Developers, organizations, and users must be accountable for the decisions made by AI and must establish mechanisms for redress in case of harm.\n",
       "\n",
       "3. **Fairness and Non-Discrimination**: AI applications should avoid biases and discriminatory practices. This includes ensuring that data used for training does not reinforce existing social inequalities and that outcomes are fair across different demographics.\n",
       "\n",
       "4. **Privacy and Data Protection**: AI systems must respect individuals’ privacy and safeguard personal data. This requires adherence to data protection regulations and the establishment of ethical data handling practices.\n",
       "\n",
       "5. **Beneficence**: AI should be developed and deployed in ways that promote the well-being of individuals and society as a whole. This means prioritizing applications that contribute positively to societal challenges, such as healthcare, education, and environmental sustainability.\n",
       "\n",
       "6. **Inclusivity and Accessibility**: AI technologies should be designed to be accessible to all and consider diverse user perspectives. This involves actively involving different communities in the design process and ensuring that technologies do not marginalize certain groups.\n",
       "\n",
       "7. **Sustainability**: The development of AI should consider the environmental impact, aiming for energy-efficient solutions and minimizing carbon footprints associated with training complex models.\n",
       "\n",
       "8. **Human-Centric Design**: AI should augment human capabilities and enhance human agency, rather than replacing humans or diminishing their roles. Keeping humans in the loop ensures decisions made by AI align with human values and ethics.\n",
       "\n",
       "### Addressing Potential Conflicts:\n",
       "Conflicts can arise between these principles. For instance, a push for transparency may conflict with the need for privacy, as releasing algorithms or data might expose sensitive information. To address such conflicts, the following strategies could be employed:\n",
       "\n",
       "- **Contextual Guidelines**: Establish context-specific guidelines to determine when and how principles should be prioritized, based on the use case and potential impact.\n",
       "\n",
       "- **Stakeholder Engagement**: Involve stakeholders—including ethicists, impacted communities, and industry experts—in the decision-making process to ensure a diverse range of perspectives is considered in ethical dilemmas.\n",
       "\n",
       "- **Adaptive Governance**: Develop a governance model that can adapt over time to changes in technology and societal norms. This would allow the framework to evolve and refine how principles are balanced.\n",
       "\n",
       "- **Impact Assessments**: Regularly conduct ethical impact assessments to evaluate the implications of AI decisions and implementations to help identify potential conflicts and adjust practices accordingly.\n",
       "\n",
       "- **Robust Oversight Mechanisms**: Establish an independent oversight body that can review AI deployments and ensure compliance with ethical standards, providing checks and balances against misuse or unintentional harm.\n",
       "\n",
       "Overall, an ethical framework for AI should be dynamic, rotating around ongoing discourse and adaptation to societal needs while fostering innovation responsibly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4o-mini']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Ethical Framework for AI: Balancing Innovation and Society\n",
       "\n",
       "If designing such a framework, I would prioritize these core principles:\n",
       "\n",
       "## Key Principles\n",
       "- **Human welfare and dignity**: AI systems should enhance human wellbeing while respecting autonomy\n",
       "- **Fairness and non-discrimination**: Systems must operate equitably across different populations\n",
       "- **Transparency and explainability**: Decision-making processes should be understandable to those affected\n",
       "- **Accountability**: Clear responsibility structures for AI outcomes\n",
       "- **Safety and robustness**: Systems should be reliable and resilient against misuse\n",
       "- **Privacy**: Protection of personal data and information boundaries\n",
       "\n",
       "## Addressing Conflicts\n",
       "\n",
       "When principles clash, I would implement:\n",
       "\n",
       "1. **Deliberative processes**: Multi-stakeholder forums including affected communities\n",
       "2. **Contextual prioritization**: Recognizing that different domains may require different balancing\n",
       "3. **Minimum ethical thresholds**: Establishing non-negotiable baselines for each principle\n",
       "4. **Iterative adjustment**: Regularly revisiting the framework as technology and society evolve\n",
       "\n",
       "The hardest tensions often arise between innovation and protection. I'd advocate for a \"responsible innovation\" approach where advancement continues but with appropriate safeguards and inclusive participation in governance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, designing an ethical framework for AI that balances innovation with societal impact is a complex challenge. Here's how I'd approach it, prioritizing key principles and outlining how to address potential conflicts:\n",
       "\n",
       "**I. Core Principles:**\n",
       "\n",
       "1.  **Beneficence (Do Good) & Non-Maleficence (Do No Harm):**\n",
       "    *   **Definition:** AI systems should be designed and used to benefit humanity, improving quality of life, addressing societal challenges, and minimizing harm. This encompasses physical, psychological, economic, and social well-being.\n",
       "    *   **Implementation:**\n",
       "        *   **Impact Assessments:**  Mandatory ethical impact assessments prior to deployment, analyzing potential benefits and harms across diverse stakeholder groups.\n",
       "        *   **Safety-by-Design:**  Incorporating safety mechanisms and fail-safe protocols into the AI system's architecture.\n",
       "        *   **Human Oversight:**  Maintaining human control and oversight, especially in high-stakes decisions (e.g., healthcare, criminal justice).\n",
       "        *   **Monitoring and Mitigation:** Continuous monitoring of AI system performance to identify and mitigate any unforeseen negative consequences.\n",
       "    *   **Metrics:** Track positive impacts like increased efficiency in resource allocation, improved healthcare outcomes, reduced poverty, as well as negative ones like job displacement, algorithmic bias, and privacy breaches.\n",
       "\n",
       "2.  **Fairness & Justice:**\n",
       "    *   **Definition:** AI systems should be equitable and avoid perpetuating or amplifying existing societal biases. Outcomes should be fair and just for all individuals and groups, regardless of protected characteristics (e.g., race, gender, religion, socioeconomic status).\n",
       "    *   **Implementation:**\n",
       "        *   **Data Audits:** Rigorous auditing of training data to identify and mitigate biases.\n",
       "        *   **Algorithmic Transparency:** Providing transparency into the decision-making processes of AI systems, particularly in areas where fairness is critical.\n",
       "        *   **Bias Detection & Mitigation:** Employing techniques to detect and mitigate algorithmic bias throughout the AI lifecycle (data collection, model training, deployment, and monitoring).\n",
       "        *   **Diverse Development Teams:** Ensuring diverse perspectives are represented in the design and development of AI systems.\n",
       "    *   **Metrics:** Measure fairness across different demographic groups using metrics like disparate impact, equal opportunity, and predictive rate parity. Track and address any disparities identified.\n",
       "\n",
       "3.  **Transparency & Explainability:**\n",
       "    *   **Definition:** The inner workings of AI systems, especially those that make important decisions, should be understandable to relevant stakeholders. Explanations should be provided for how decisions are made, allowing for scrutiny and accountability.\n",
       "    *   **Implementation:**\n",
       "        *   **Explainable AI (XAI) Techniques:** Utilizing XAI methods to provide insights into AI decision-making processes.\n",
       "        *   **Documentation:** Providing clear and accessible documentation about the AI system's design, training data, limitations, and intended use.\n",
       "        *   **Auditing & Review:** Establishing mechanisms for auditing and reviewing AI systems to ensure they are operating as intended and that their decisions are justified.\n",
       "        *   **Right to Explanation:** Granting individuals the right to receive an explanation for decisions made by AI systems that affect them.\n",
       "    *   **Metrics:** Measure the degree to which AI systems are understandable and interpretable, using metrics like explanation accuracy, coverage, and user satisfaction with explanations.\n",
       "\n",
       "4.  **Accountability & Responsibility:**\n",
       "    *   **Definition:** Clear lines of responsibility should be established for the design, development, deployment, and use of AI systems. Individuals and organizations should be held accountable for the consequences of AI systems' actions.\n",
       "    *   **Implementation:**\n",
       "        *   **Defined Roles & Responsibilities:** Clearly defining roles and responsibilities for each stage of the AI lifecycle.\n",
       "        *   **Auditing & Monitoring:** Implementing auditing and monitoring mechanisms to track the performance of AI systems and identify any potential issues.\n",
       "        *   **Remedial Mechanisms:** Establishing mechanisms for redress and compensation in cases where AI systems cause harm.\n",
       "        *   **Ethical Review Boards:** Creating ethical review boards to oversee the development and deployment of AI systems.\n",
       "    *   **Metrics:** Track the effectiveness of accountability mechanisms in preventing harm and ensuring responsible AI development and deployment. Measure the number of incidents involving AI-related harm, the effectiveness of redress mechanisms, and the level of public trust in AI systems.\n",
       "\n",
       "5.  **Privacy & Data Governance:**\n",
       "    *   **Definition:** AI systems should respect individuals' privacy rights and protect their personal data. Data should be collected, used, and stored responsibly and securely.\n",
       "    *   **Implementation:**\n",
       "        *   **Data Minimization:** Collecting only the data that is necessary for the intended purpose.\n",
       "        *   **Data Security:** Implementing robust security measures to protect data from unauthorized access, use, or disclosure.\n",
       "        *   **Privacy-Preserving Technologies:** Employing privacy-preserving technologies (e.g., differential privacy, federated learning) to minimize the risk of data breaches and protect individual privacy.\n",
       "        *   **User Consent & Control:** Obtaining informed consent from individuals before collecting and using their data, and giving them control over their data.\n",
       "    *   **Metrics:** Track the number of data breaches, the level of user control over their data, and the adoption of privacy-preserving technologies.\n",
       "\n",
       "6.  **Sustainability:**\n",
       "    *   **Definition:** AI development and deployment should be environmentally sustainable, minimizing its carbon footprint and resource consumption. This also extends to the long-term social and economic sustainability of AI adoption.\n",
       "    *   **Implementation:**\n",
       "        *   **Energy Efficiency:** Optimizing AI algorithms and infrastructure for energy efficiency.\n",
       "        *   **Responsible Resource Use:**  Minimizing the use of scarce resources (e.g., rare earth minerals) in AI development.\n",
       "        *   **Life Cycle Assessment:** Conducting life cycle assessments of AI systems to assess their environmental impact.\n",
       "        *   **Promoting Green AI:** Fostering research and development in green AI technologies.\n",
       "    *   **Metrics:** Track the energy consumption, resource usage, and carbon footprint of AI systems. Measure the adoption of green AI technologies and practices.\n",
       "\n",
       "**II. Addressing Potential Conflicts Between Principles:**\n",
       "\n",
       "Conflicts between these principles are inevitable. Here's how to navigate them:\n",
       "\n",
       "1.  **Prioritization Framework:**\n",
       "    *   **Context-Specific Prioritization:**  Recognize that the relative importance of different principles will vary depending on the specific context and application of the AI system. For example, in medical diagnosis, beneficence and non-maleficence might take precedence over transparency in certain emergency situations.\n",
       "    *   **Deliberative Processes:**  Establish clear processes for deliberating about and resolving conflicts between ethical principles, involving diverse stakeholders (e.g., ethicists, developers, users, policymakers).\n",
       "    *   **Hierarchical Structure (with Caution):**  While not always ideal, a hierarchical structure *might* be necessary in certain narrow cases.  For instance, laws protecting fundamental human rights *might* supersede other considerations. However, any hierarchical structure should be carefully justified and subject to ongoing review.\n",
       "\n",
       "2.  **Trade-off Analysis:**\n",
       "    *   **Transparency about Trade-offs:**  Acknowledge and communicate openly about the trade-offs that are being made when prioritizing one principle over another.\n",
       "    *   **Minimizing Harm:**  When making trade-offs, prioritize minimizing harm to individuals and society.\n",
       "    *   **Seeking Synergies:**  Explore opportunities to achieve multiple ethical goals simultaneously.  For example, using privacy-preserving techniques can also enhance data security.\n",
       "\n",
       "3.  **Robust Governance & Oversight:**\n",
       "    *   **Multi-Stakeholder Governance:**  Establish governance structures that involve diverse stakeholders in the oversight of AI development and deployment.\n",
       "    *   **Independent Audits:**  Conduct regular independent audits of AI systems to assess their compliance with ethical principles.\n",
       "    *   **Regulatory Frameworks:**  Develop clear regulatory frameworks that provide guidance on the ethical development and use of AI.\n",
       "\n",
       "4.  **Continuous Learning & Adaptation:**\n",
       "    *   **Iterative Ethical Review:**  Regularly review and update the ethical framework to reflect new developments in AI and evolving societal values.\n",
       "    *   **Feedback Mechanisms:**  Establish mechanisms for gathering feedback from users and the public about the ethical implications of AI systems.\n",
       "    *   **Research & Development:**  Invest in research and development on ethical AI to address emerging challenges and opportunities.\n",
       "\n",
       "**III. Example Scenario: Facial Recognition Technology:**\n",
       "\n",
       "*   **Principle Conflict:**  Innovation in facial recognition can improve security (beneficence), but also threaten privacy and potentially lead to biased surveillance (non-maleficence, fairness).\n",
       "*   **Resolution:**\n",
       "    *   **Contextual Limitations:**  Restrict the use of facial recognition to specific, high-risk scenarios (e.g., airport security, criminal investigations) and prohibit its use in public spaces for general surveillance.\n",
       "    *   **Transparency & Accountability:**  Require clear signage indicating when facial recognition is being used, and establish mechanisms for oversight and accountability.\n",
       "    *   **Bias Mitigation:**  Invest in research and development to mitigate bias in facial recognition algorithms.\n",
       "    *   **Data Security:**  Implement strong data security measures to protect data from unauthorized access and misuse.\n",
       "    *   **Human Review:** Require human review of facial recognition matches before any action is taken.\n",
       "\n",
       "**IV. Key Considerations for Success:**\n",
       "\n",
       "*   **International Cooperation:**  Ethical AI development requires international cooperation to ensure that ethical principles are consistent across borders.\n",
       "*   **Education & Awareness:**  Promote education and awareness about the ethical implications of AI among developers, users, and the public.\n",
       "*   **Incentives:**  Provide incentives for organizations to develop and deploy AI systems ethically.\n",
       "\n",
       "By adopting these principles and implementing these strategies, we can create an ethical framework for AI that promotes innovation while safeguarding human values and ensuring that AI benefits all of humanity. It's an ongoing process that requires constant vigilance, adaptation, and a commitment to ethical principles.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing an ethical framework for AI that balances innovation with societal impact requires prioritizing principles that ensure responsible development while fostering progress. Below are the key principles I would prioritize and strategies to address conflicts between them:\n",
       "\n",
       "### **Key Principles:**\n",
       "1. **Transparency & Explainability**  \n",
       "   - AI systems should be understandable to stakeholders (users, developers, regulators).  \n",
       "   - Decisions made by AI should be explainable, especially in high-stakes domains (healthcare, criminal justice).  \n",
       "\n",
       "2. **Fairness & Non-Discrimination**  \n",
       "   - AI should avoid biases in data and algorithms that could harm marginalized groups.  \n",
       "   - Regular audits should assess fairness across demographic groups.  \n",
       "\n",
       "3. **Accountability & Responsibility**  \n",
       "   - Clear lines of responsibility for AI outcomes (developers, deployers, regulators).  \n",
       "   - Mechanisms for redress if AI causes harm.  \n",
       "\n",
       "4. **Privacy & Data Protection**  \n",
       "   - Minimize data collection and ensure robust security.  \n",
       "   - Comply with regulations like GDPR and ensure user consent.  \n",
       "\n",
       "5. **Safety & Robustness**  \n",
       "   - AI systems must be reliable, secure, and resilient against misuse.  \n",
       "   - Rigorous testing before deployment, especially in critical applications.  \n",
       "\n",
       "6. **Human Autonomy & Control**  \n",
       "   - AI should augment, not replace, human decision-making in sensitive areas.  \n",
       "   - Users should have meaningful oversight and opt-out options.  \n",
       "\n",
       "7. **Societal Benefit & Sustainability**  \n",
       "   - AI should contribute to public good (e.g., healthcare, climate solutions).  \n",
       "   - Avoid applications that exacerbate inequality or environmental harm.  \n",
       "\n",
       "8. **Innovation & Openness**  \n",
       "   - Encourage research and collaboration while mitigating risks.  \n",
       "   - Balance proprietary interests with open-source contributions for public benefit.  \n",
       "\n",
       "### **Addressing Conflicts Between Principles:**  \n",
       "Conflicts may arise—e.g., **privacy vs. innovation** (data restrictions may limit AI training) or **autonomy vs. safety** (strict controls may stifle creativity). Strategies to resolve tensions:  \n",
       "\n",
       "- **Risk-Benefit Analysis:** Weigh societal harms against potential gains (e.g., facial recognition for security vs. privacy risks).  \n",
       "- **Stakeholder Engagement:** Involve diverse voices (technologists, ethicists, policymakers, affected communities) in decision-making.  \n",
       "- **Tiered Governance:** Stricter rules for high-risk applications (medical AI) vs. lighter oversight for low-risk uses (recommendation systems).  \n",
       "- **Adaptive Policies:** Update guidelines as technology evolves, balancing flexibility with safeguards.  \n",
       "- **Ethical Trade-off Frameworks:** Use decision matrices to evaluate trade-offs (e.g., prioritizing fairness over speed in hiring algorithms).  \n",
       "\n",
       "### **Conclusion:**  \n",
       "A robust ethical AI framework must be **dynamic, inclusive, and context-aware**, ensuring innovation thrives while minimizing harm. By embedding these principles in governance structures and fostering ongoing dialogue, we can navigate conflicts responsibly.  \n",
       "\n",
       "Would you emphasize any additional principles or conflict-resolution approaches?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing an ethical framework for artificial intelligence (AI) that balances innovation with societal impact requires careful consideration of several key principles. Here are some principles I would prioritize, along with suggestions for addressing potential conflicts between them:\n",
       "\n",
       "1. **Transparency**: Ensure that AI systems are transparent in their decision-making processes, allowing users and stakeholders to understand how they arrive at conclusions.\n",
       "\t* Addressing conflict: When deciding on transparency levels, consider the level of understanding required by different stakeholders (e.g., general public vs. experts).\n",
       "\n",
       "2. **Accountability**: Hold developers, deployers, and users accountable for AI system development, deployment, and performance, ensuring that all parties are responsible for negative consequences.\n",
       "\t* Addressing conflict: Establish clear lines of accountability, such as defining roles and responsibilities in AI-related decision-making.\n",
       "\n",
       "3. **Fairness**: Ensure that AI systems do not perpetuate or exacerbate existing societal biases, discrimination, or inequities.\n",
       "\t* Addressing conflict: Implement robust auditing mechanisms to detect bias, monitor demographics' impact on decisions made by the system\n",
       "\n",
       "4. **Privacy**: Protect users' privacy and security rights by preserving personal data and protecting against unauthorized access or misuse.\n",
       "\t* Addressing conflict: Utilize cryptography to safeguard user information in AI-driven decision-making.\n",
       "\n",
       "5. **Purpose Limitation**: Ensure that AI systems operate within established ethical limits, avoiding actions which could cause significant harm or negative social impact.\n",
       "\t* Addressing conflict: Establish a set of specific guidelines and regulations that outline the maximum extent in which AI should be utilized for different scenarios.\n",
       "\n",
       "6. **Human Wellbeing**: Prioritize human well-being and consider potential consequences on people's health, happiness, safety, and other aspects when developing AI-driven solutions.\n",
       "\t* Addressing conflict: Evaluate systems using multiple metrics: one must balance outcomes with the side effects felt by individuals through direct or indirect means \n",
       "\n",
       "7. **Autonomy**: Recognize the autonomy of humans in areas where AI cannot improve decisions, taking care that both are valued equally, and no particular person receives a 'preferential advantage'.\n",
       "\n",
       "8.  Resilience and Safety: Ensure that AI systems can evolve to changing scenarios and conditions effectively without undermining basic human values.\n",
       "\t* Addressing conflict: Continuously test and train in controlled experiments, incorporating knowledge generated from those tests into safety testing protocols"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'claude-3-7-sonnet-latest', 'gemini-2.0-flash', 'llama3.2']\n",
      "['Designing an ethical framework for artificial intelligence (AI) is a complex '\n",
      " 'task that requires careful consideration of various principles to balance '\n",
      " 'innovation with societal impact. Here are some key principles I would '\n",
      " 'prioritize:\\n'\n",
      " '\\n'\n",
      " '1. **Transparency**: AI systems should be designed to be transparent in '\n",
      " 'their decision-making processes. This includes providing clear explanations '\n",
      " 'of how algorithms work and allowing stakeholders to understand how decisions '\n",
      " 'are made.\\n'\n",
      " '\\n'\n",
      " '2. **Accountability**: There should be clear lines of responsibility for AI '\n",
      " 'systems and their outcomes. Developers, organizations, and users must be '\n",
      " 'accountable for the decisions made by AI and must establish mechanisms for '\n",
      " 'redress in case of harm.\\n'\n",
      " '\\n'\n",
      " '3. **Fairness and Non-Discrimination**: AI applications should avoid biases '\n",
      " 'and discriminatory practices. This includes ensuring that data used for '\n",
      " 'training does not reinforce existing social inequalities and that outcomes '\n",
      " 'are fair across different demographics.\\n'\n",
      " '\\n'\n",
      " '4. **Privacy and Data Protection**: AI systems must respect individuals’ '\n",
      " 'privacy and safeguard personal data. This requires adherence to data '\n",
      " 'protection regulations and the establishment of ethical data handling '\n",
      " 'practices.\\n'\n",
      " '\\n'\n",
      " '5. **Beneficence**: AI should be developed and deployed in ways that promote '\n",
      " 'the well-being of individuals and society as a whole. This means '\n",
      " 'prioritizing applications that contribute positively to societal challenges, '\n",
      " 'such as healthcare, education, and environmental sustainability.\\n'\n",
      " '\\n'\n",
      " '6. **Inclusivity and Accessibility**: AI technologies should be designed to '\n",
      " 'be accessible to all and consider diverse user perspectives. This involves '\n",
      " 'actively involving different communities in the design process and ensuring '\n",
      " 'that technologies do not marginalize certain groups.\\n'\n",
      " '\\n'\n",
      " '7. **Sustainability**: The development of AI should consider the '\n",
      " 'environmental impact, aiming for energy-efficient solutions and minimizing '\n",
      " 'carbon footprints associated with training complex models.\\n'\n",
      " '\\n'\n",
      " '8. **Human-Centric Design**: AI should augment human capabilities and '\n",
      " 'enhance human agency, rather than replacing humans or diminishing their '\n",
      " 'roles. Keeping humans in the loop ensures decisions made by AI align with '\n",
      " 'human values and ethics.\\n'\n",
      " '\\n'\n",
      " '### Addressing Potential Conflicts:\\n'\n",
      " 'Conflicts can arise between these principles. For instance, a push for '\n",
      " 'transparency may conflict with the need for privacy, as releasing algorithms '\n",
      " 'or data might expose sensitive information. To address such conflicts, the '\n",
      " 'following strategies could be employed:\\n'\n",
      " '\\n'\n",
      " '- **Contextual Guidelines**: Establish context-specific guidelines to '\n",
      " 'determine when and how principles should be prioritized, based on the use '\n",
      " 'case and potential impact.\\n'\n",
      " '\\n'\n",
      " '- **Stakeholder Engagement**: Involve stakeholders—including ethicists, '\n",
      " 'impacted communities, and industry experts—in the decision-making process to '\n",
      " 'ensure a diverse range of perspectives is considered in ethical dilemmas.\\n'\n",
      " '\\n'\n",
      " '- **Adaptive Governance**: Develop a governance model that can adapt over '\n",
      " 'time to changes in technology and societal norms. This would allow the '\n",
      " 'framework to evolve and refine how principles are balanced.\\n'\n",
      " '\\n'\n",
      " '- **Impact Assessments**: Regularly conduct ethical impact assessments to '\n",
      " 'evaluate the implications of AI decisions and implementations to help '\n",
      " 'identify potential conflicts and adjust practices accordingly.\\n'\n",
      " '\\n'\n",
      " '- **Robust Oversight Mechanisms**: Establish an independent oversight body '\n",
      " 'that can review AI deployments and ensure compliance with ethical standards, '\n",
      " 'providing checks and balances against misuse or unintentional harm.\\n'\n",
      " '\\n'\n",
      " 'Overall, an ethical framework for AI should be dynamic, rotating around '\n",
      " 'ongoing discourse and adaptation to societal needs while fostering '\n",
      " 'innovation responsibly.',\n",
      " '# Ethical Framework for AI: Balancing Innovation and Society\\n'\n",
      " '\\n'\n",
      " 'If designing such a framework, I would prioritize these core principles:\\n'\n",
      " '\\n'\n",
      " '## Key Principles\\n'\n",
      " '- **Human welfare and dignity**: AI systems should enhance human wellbeing '\n",
      " 'while respecting autonomy\\n'\n",
      " '- **Fairness and non-discrimination**: Systems must operate equitably across '\n",
      " 'different populations\\n'\n",
      " '- **Transparency and explainability**: Decision-making processes should be '\n",
      " 'understandable to those affected\\n'\n",
      " '- **Accountability**: Clear responsibility structures for AI outcomes\\n'\n",
      " '- **Safety and robustness**: Systems should be reliable and resilient '\n",
      " 'against misuse\\n'\n",
      " '- **Privacy**: Protection of personal data and information boundaries\\n'\n",
      " '\\n'\n",
      " '## Addressing Conflicts\\n'\n",
      " '\\n'\n",
      " 'When principles clash, I would implement:\\n'\n",
      " '\\n'\n",
      " '1. **Deliberative processes**: Multi-stakeholder forums including affected '\n",
      " 'communities\\n'\n",
      " '2. **Contextual prioritization**: Recognizing that different domains may '\n",
      " 'require different balancing\\n'\n",
      " '3. **Minimum ethical thresholds**: Establishing non-negotiable baselines for '\n",
      " 'each principle\\n'\n",
      " '4. **Iterative adjustment**: Regularly revisiting the framework as '\n",
      " 'technology and society evolve\\n'\n",
      " '\\n'\n",
      " \"The hardest tensions often arise between innovation and protection. I'd \"\n",
      " 'advocate for a \"responsible innovation\" approach where advancement continues '\n",
      " 'but with appropriate safeguards and inclusive participation in governance.',\n",
      " 'Okay, designing an ethical framework for AI that balances innovation with '\n",
      " \"societal impact is a complex challenge. Here's how I'd approach it, \"\n",
      " 'prioritizing key principles and outlining how to address potential '\n",
      " 'conflicts:\\n'\n",
      " '\\n'\n",
      " '**I. Core Principles:**\\n'\n",
      " '\\n'\n",
      " '1.  **Beneficence (Do Good) & Non-Maleficence (Do No Harm):**\\n'\n",
      " '    *   **Definition:** AI systems should be designed and used to benefit '\n",
      " 'humanity, improving quality of life, addressing societal challenges, and '\n",
      " 'minimizing harm. This encompasses physical, psychological, economic, and '\n",
      " 'social well-being.\\n'\n",
      " '    *   **Implementation:**\\n'\n",
      " '        *   **Impact Assessments:**  Mandatory ethical impact assessments '\n",
      " 'prior to deployment, analyzing potential benefits and harms across diverse '\n",
      " 'stakeholder groups.\\n'\n",
      " '        *   **Safety-by-Design:**  Incorporating safety mechanisms and '\n",
      " \"fail-safe protocols into the AI system's architecture.\\n\"\n",
      " '        *   **Human Oversight:**  Maintaining human control and oversight, '\n",
      " 'especially in high-stakes decisions (e.g., healthcare, criminal justice).\\n'\n",
      " '        *   **Monitoring and Mitigation:** Continuous monitoring of AI '\n",
      " 'system performance to identify and mitigate any unforeseen negative '\n",
      " 'consequences.\\n'\n",
      " '    *   **Metrics:** Track positive impacts like increased efficiency in '\n",
      " 'resource allocation, improved healthcare outcomes, reduced poverty, as well '\n",
      " 'as negative ones like job displacement, algorithmic bias, and privacy '\n",
      " 'breaches.\\n'\n",
      " '\\n'\n",
      " '2.  **Fairness & Justice:**\\n'\n",
      " '    *   **Definition:** AI systems should be equitable and avoid '\n",
      " 'perpetuating or amplifying existing societal biases. Outcomes should be fair '\n",
      " 'and just for all individuals and groups, regardless of protected '\n",
      " 'characteristics (e.g., race, gender, religion, socioeconomic status).\\n'\n",
      " '    *   **Implementation:**\\n'\n",
      " '        *   **Data Audits:** Rigorous auditing of training data to identify '\n",
      " 'and mitigate biases.\\n'\n",
      " '        *   **Algorithmic Transparency:** Providing transparency into the '\n",
      " 'decision-making processes of AI systems, particularly in areas where '\n",
      " 'fairness is critical.\\n'\n",
      " '        *   **Bias Detection & Mitigation:** Employing techniques to detect '\n",
      " 'and mitigate algorithmic bias throughout the AI lifecycle (data collection, '\n",
      " 'model training, deployment, and monitoring).\\n'\n",
      " '        *   **Diverse Development Teams:** Ensuring diverse perspectives are '\n",
      " 'represented in the design and development of AI systems.\\n'\n",
      " '    *   **Metrics:** Measure fairness across different demographic groups '\n",
      " 'using metrics like disparate impact, equal opportunity, and predictive rate '\n",
      " 'parity. Track and address any disparities identified.\\n'\n",
      " '\\n'\n",
      " '3.  **Transparency & Explainability:**\\n'\n",
      " '    *   **Definition:** The inner workings of AI systems, especially those '\n",
      " 'that make important decisions, should be understandable to relevant '\n",
      " 'stakeholders. Explanations should be provided for how decisions are made, '\n",
      " 'allowing for scrutiny and accountability.\\n'\n",
      " '    *   **Implementation:**\\n'\n",
      " '        *   **Explainable AI (XAI) Techniques:** Utilizing XAI methods to '\n",
      " 'provide insights into AI decision-making processes.\\n'\n",
      " '        *   **Documentation:** Providing clear and accessible documentation '\n",
      " \"about the AI system's design, training data, limitations, and intended use.\\n\"\n",
      " '        *   **Auditing & Review:** Establishing mechanisms for auditing and '\n",
      " 'reviewing AI systems to ensure they are operating as intended and that their '\n",
      " 'decisions are justified.\\n'\n",
      " '        *   **Right to Explanation:** Granting individuals the right to '\n",
      " 'receive an explanation for decisions made by AI systems that affect them.\\n'\n",
      " '    *   **Metrics:** Measure the degree to which AI systems are '\n",
      " 'understandable and interpretable, using metrics like explanation accuracy, '\n",
      " 'coverage, and user satisfaction with explanations.\\n'\n",
      " '\\n'\n",
      " '4.  **Accountability & Responsibility:**\\n'\n",
      " '    *   **Definition:** Clear lines of responsibility should be established '\n",
      " 'for the design, development, deployment, and use of AI systems. Individuals '\n",
      " 'and organizations should be held accountable for the consequences of AI '\n",
      " \"systems' actions.\\n\"\n",
      " '    *   **Implementation:**\\n'\n",
      " '        *   **Defined Roles & Responsibilities:** Clearly defining roles and '\n",
      " 'responsibilities for each stage of the AI lifecycle.\\n'\n",
      " '        *   **Auditing & Monitoring:** Implementing auditing and monitoring '\n",
      " 'mechanisms to track the performance of AI systems and identify any potential '\n",
      " 'issues.\\n'\n",
      " '        *   **Remedial Mechanisms:** Establishing mechanisms for redress and '\n",
      " 'compensation in cases where AI systems cause harm.\\n'\n",
      " '        *   **Ethical Review Boards:** Creating ethical review boards to '\n",
      " 'oversee the development and deployment of AI systems.\\n'\n",
      " '    *   **Metrics:** Track the effectiveness of accountability mechanisms in '\n",
      " 'preventing harm and ensuring responsible AI development and deployment. '\n",
      " 'Measure the number of incidents involving AI-related harm, the effectiveness '\n",
      " 'of redress mechanisms, and the level of public trust in AI systems.\\n'\n",
      " '\\n'\n",
      " '5.  **Privacy & Data Governance:**\\n'\n",
      " \"    *   **Definition:** AI systems should respect individuals' privacy \"\n",
      " 'rights and protect their personal data. Data should be collected, used, and '\n",
      " 'stored responsibly and securely.\\n'\n",
      " '    *   **Implementation:**\\n'\n",
      " '        *   **Data Minimization:** Collecting only the data that is '\n",
      " 'necessary for the intended purpose.\\n'\n",
      " '        *   **Data Security:** Implementing robust security measures to '\n",
      " 'protect data from unauthorized access, use, or disclosure.\\n'\n",
      " '        *   **Privacy-Preserving Technologies:** Employing '\n",
      " 'privacy-preserving technologies (e.g., differential privacy, federated '\n",
      " 'learning) to minimize the risk of data breaches and protect individual '\n",
      " 'privacy.\\n'\n",
      " '        *   **User Consent & Control:** Obtaining informed consent from '\n",
      " 'individuals before collecting and using their data, and giving them control '\n",
      " 'over their data.\\n'\n",
      " '    *   **Metrics:** Track the number of data breaches, the level of user '\n",
      " 'control over their data, and the adoption of privacy-preserving '\n",
      " 'technologies.\\n'\n",
      " '\\n'\n",
      " '6.  **Sustainability:**\\n'\n",
      " '    *   **Definition:** AI development and deployment should be '\n",
      " 'environmentally sustainable, minimizing its carbon footprint and resource '\n",
      " 'consumption. This also extends to the long-term social and economic '\n",
      " 'sustainability of AI adoption.\\n'\n",
      " '    *   **Implementation:**\\n'\n",
      " '        *   **Energy Efficiency:** Optimizing AI algorithms and '\n",
      " 'infrastructure for energy efficiency.\\n'\n",
      " '        *   **Responsible Resource Use:**  Minimizing the use of scarce '\n",
      " 'resources (e.g., rare earth minerals) in AI development.\\n'\n",
      " '        *   **Life Cycle Assessment:** Conducting life cycle assessments of '\n",
      " 'AI systems to assess their environmental impact.\\n'\n",
      " '        *   **Promoting Green AI:** Fostering research and development in '\n",
      " 'green AI technologies.\\n'\n",
      " '    *   **Metrics:** Track the energy consumption, resource usage, and '\n",
      " 'carbon footprint of AI systems. Measure the adoption of green AI '\n",
      " 'technologies and practices.\\n'\n",
      " '\\n'\n",
      " '**II. Addressing Potential Conflicts Between Principles:**\\n'\n",
      " '\\n'\n",
      " \"Conflicts between these principles are inevitable. Here's how to navigate \"\n",
      " 'them:\\n'\n",
      " '\\n'\n",
      " '1.  **Prioritization Framework:**\\n'\n",
      " '    *   **Context-Specific Prioritization:**  Recognize that the relative '\n",
      " 'importance of different principles will vary depending on the specific '\n",
      " 'context and application of the AI system. For example, in medical diagnosis, '\n",
      " 'beneficence and non-maleficence might take precedence over transparency in '\n",
      " 'certain emergency situations.\\n'\n",
      " '    *   **Deliberative Processes:**  Establish clear processes for '\n",
      " 'deliberating about and resolving conflicts between ethical principles, '\n",
      " 'involving diverse stakeholders (e.g., ethicists, developers, users, '\n",
      " 'policymakers).\\n'\n",
      " '    *   **Hierarchical Structure (with Caution):**  While not always ideal, '\n",
      " 'a hierarchical structure *might* be necessary in certain narrow cases.  For '\n",
      " 'instance, laws protecting fundamental human rights *might* supersede other '\n",
      " 'considerations. However, any hierarchical structure should be carefully '\n",
      " 'justified and subject to ongoing review.\\n'\n",
      " '\\n'\n",
      " '2.  **Trade-off Analysis:**\\n'\n",
      " '    *   **Transparency about Trade-offs:**  Acknowledge and communicate '\n",
      " 'openly about the trade-offs that are being made when prioritizing one '\n",
      " 'principle over another.\\n'\n",
      " '    *   **Minimizing Harm:**  When making trade-offs, prioritize minimizing '\n",
      " 'harm to individuals and society.\\n'\n",
      " '    *   **Seeking Synergies:**  Explore opportunities to achieve multiple '\n",
      " 'ethical goals simultaneously.  For example, using privacy-preserving '\n",
      " 'techniques can also enhance data security.\\n'\n",
      " '\\n'\n",
      " '3.  **Robust Governance & Oversight:**\\n'\n",
      " '    *   **Multi-Stakeholder Governance:**  Establish governance structures '\n",
      " 'that involve diverse stakeholders in the oversight of AI development and '\n",
      " 'deployment.\\n'\n",
      " '    *   **Independent Audits:**  Conduct regular independent audits of AI '\n",
      " 'systems to assess their compliance with ethical principles.\\n'\n",
      " '    *   **Regulatory Frameworks:**  Develop clear regulatory frameworks that '\n",
      " 'provide guidance on the ethical development and use of AI.\\n'\n",
      " '\\n'\n",
      " '4.  **Continuous Learning & Adaptation:**\\n'\n",
      " '    *   **Iterative Ethical Review:**  Regularly review and update the '\n",
      " 'ethical framework to reflect new developments in AI and evolving societal '\n",
      " 'values.\\n'\n",
      " '    *   **Feedback Mechanisms:**  Establish mechanisms for gathering '\n",
      " 'feedback from users and the public about the ethical implications of AI '\n",
      " 'systems.\\n'\n",
      " '    *   **Research & Development:**  Invest in research and development on '\n",
      " 'ethical AI to address emerging challenges and opportunities.\\n'\n",
      " '\\n'\n",
      " '**III. Example Scenario: Facial Recognition Technology:**\\n'\n",
      " '\\n'\n",
      " '*   **Principle Conflict:**  Innovation in facial recognition can improve '\n",
      " 'security (beneficence), but also threaten privacy and potentially lead to '\n",
      " 'biased surveillance (non-maleficence, fairness).\\n'\n",
      " '*   **Resolution:**\\n'\n",
      " '    *   **Contextual Limitations:**  Restrict the use of facial recognition '\n",
      " 'to specific, high-risk scenarios (e.g., airport security, criminal '\n",
      " 'investigations) and prohibit its use in public spaces for general '\n",
      " 'surveillance.\\n'\n",
      " '    *   **Transparency & Accountability:**  Require clear signage indicating '\n",
      " 'when facial recognition is being used, and establish mechanisms for '\n",
      " 'oversight and accountability.\\n'\n",
      " '    *   **Bias Mitigation:**  Invest in research and development to mitigate '\n",
      " 'bias in facial recognition algorithms.\\n'\n",
      " '    *   **Data Security:**  Implement strong data security measures to '\n",
      " 'protect data from unauthorized access and misuse.\\n'\n",
      " '    *   **Human Review:** Require human review of facial recognition matches '\n",
      " 'before any action is taken.\\n'\n",
      " '\\n'\n",
      " '**IV. Key Considerations for Success:**\\n'\n",
      " '\\n'\n",
      " '*   **International Cooperation:**  Ethical AI development requires '\n",
      " 'international cooperation to ensure that ethical principles are consistent '\n",
      " 'across borders.\\n'\n",
      " '*   **Education & Awareness:**  Promote education and awareness about the '\n",
      " 'ethical implications of AI among developers, users, and the public.\\n'\n",
      " '*   **Incentives:**  Provide incentives for organizations to develop and '\n",
      " 'deploy AI systems ethically.\\n'\n",
      " '\\n'\n",
      " 'By adopting these principles and implementing these strategies, we can '\n",
      " 'create an ethical framework for AI that promotes innovation while '\n",
      " 'safeguarding human values and ensuring that AI benefits all of humanity. '\n",
      " \"It's an ongoing process that requires constant vigilance, adaptation, and a \"\n",
      " 'commitment to ethical principles.\\n',\n",
      " 'Designing an ethical framework for artificial intelligence (AI) that '\n",
      " 'balances innovation with societal impact requires careful consideration of '\n",
      " 'several key principles. Here are some principles I would prioritize, along '\n",
      " 'with suggestions for addressing potential conflicts between them:\\n'\n",
      " '\\n'\n",
      " '1. **Transparency**: Ensure that AI systems are transparent in their '\n",
      " 'decision-making processes, allowing users and stakeholders to understand how '\n",
      " 'they arrive at conclusions.\\n'\n",
      " '\\t* Addressing conflict: When deciding on transparency levels, consider the '\n",
      " 'level of understanding required by different stakeholders (e.g., general '\n",
      " 'public vs. experts).\\n'\n",
      " '\\n'\n",
      " '2. **Accountability**: Hold developers, deployers, and users accountable for '\n",
      " 'AI system development, deployment, and performance, ensuring that all '\n",
      " 'parties are responsible for negative consequences.\\n'\n",
      " '\\t* Addressing conflict: Establish clear lines of accountability, such as '\n",
      " 'defining roles and responsibilities in AI-related decision-making.\\n'\n",
      " '\\n'\n",
      " '3. **Fairness**: Ensure that AI systems do not perpetuate or exacerbate '\n",
      " 'existing societal biases, discrimination, or inequities.\\n'\n",
      " '\\t* Addressing conflict: Implement robust auditing mechanisms to detect '\n",
      " \"bias, monitor demographics' impact on decisions made by the system\\n\"\n",
      " '\\n'\n",
      " \"4. **Privacy**: Protect users' privacy and security rights by preserving \"\n",
      " 'personal data and protecting against unauthorized access or misuse.\\n'\n",
      " '\\t* Addressing conflict: Utilize cryptography to safeguard user information '\n",
      " 'in AI-driven decision-making.\\n'\n",
      " '\\n'\n",
      " '5. **Purpose Limitation**: Ensure that AI systems operate within established '\n",
      " 'ethical limits, avoiding actions which could cause significant harm or '\n",
      " 'negative social impact.\\n'\n",
      " '\\t* Addressing conflict: Establish a set of specific guidelines and '\n",
      " 'regulations that outline the maximum extent in which AI should be utilized '\n",
      " 'for different scenarios.\\n'\n",
      " '\\n'\n",
      " '6. **Human Wellbeing**: Prioritize human well-being and consider potential '\n",
      " \"consequences on people's health, happiness, safety, and other aspects when \"\n",
      " 'developing AI-driven solutions.\\n'\n",
      " '\\t* Addressing conflict: Evaluate systems using multiple metrics: one must '\n",
      " 'balance outcomes with the side effects felt by individuals through direct or '\n",
      " 'indirect means \\n'\n",
      " '\\n'\n",
      " '7. **Autonomy**: Recognize the autonomy of humans in areas where AI cannot '\n",
      " 'improve decisions, taking care that both are valued equally, and no '\n",
      " \"particular person receives a 'preferential advantage'.\\n\"\n",
      " '\\n'\n",
      " '8.  Resilience and Safety: Ensure that AI systems can evolve to changing '\n",
      " 'scenarios and conditions effectively without undermining basic human '\n",
      " 'values.\\n'\n",
      " '\\t* Addressing conflict: Continuously test and train in controlled '\n",
      " 'experiments, incorporating knowledge generated from those tests into safety '\n",
      " 'testing protocols']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(competitors)\n",
    "pprint(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## **Competitor:** gpt-4o-mini\n",
       "\n",
       "Designing an ethical framework for artificial intelligence (AI) is a complex task that requires careful consideration of various principles to balance innovation with societal impact. Here are some key principles I would prioritize:\n",
       "\n",
       "1. **Transparency**: AI systems should be designed to be transparent in their decision-making processes. This includes providing clear explanations of how algorithms work and allowing stakeholders to understand how decisions are made.\n",
       "\n",
       "2. **Accountability**: There should be clear lines of responsibility for AI systems and their outcomes. Developers, organizations, and users must be accountable for the decisions made by AI and must establish mechanisms for redress in case of harm.\n",
       "\n",
       "3. **Fairness and Non-Discrimination**: AI applications should avoid biases and discriminatory practices. This includes ensuring that data used for training does not reinforce existing social inequalities and that outcomes are fair across different demographics.\n",
       "\n",
       "4. **Privacy and Data Protection**: AI systems must respect individuals’ privacy and safeguard personal data. This requires adherence to data protection regulations and the establishment of ethical data handling practices.\n",
       "\n",
       "5. **Beneficence**: AI should be developed and deployed in ways that promote the well-being of individuals and society as a whole. This means prioritizing applications that contribute positively to societal challenges, such as healthcare, education, and environmental sustainability.\n",
       "\n",
       "6. **Inclusivity and Accessibility**: AI technologies should be designed to be accessible to all and consider diverse user perspectives. This involves actively involving different communities in the design process and ensuring that technologies do not marginalize certain groups.\n",
       "\n",
       "7. **Sustainability**: The development of AI should consider the environmental impact, aiming for energy-efficient solutions and minimizing carbon footprints associated with training complex models.\n",
       "\n",
       "8. **Human-Centric Design**: AI should augment human capabilities and enhance human agency, rather than replacing humans or diminishing their roles. Keeping humans in the loop ensures decisions made by AI align with human values and ethics.\n",
       "\n",
       "### Addressing Potential Conflicts:\n",
       "Conflicts can arise between these principles. For instance, a push for transparency may conflict with the need for privacy, as releasing algorithms or data might expose sensitive information. To address such conflicts, the following strategies could be employed:\n",
       "\n",
       "- **Contextual Guidelines**: Establish context-specific guidelines to determine when and how principles should be prioritized, based on the use case and potential impact.\n",
       "\n",
       "- **Stakeholder Engagement**: Involve stakeholders—including ethicists, impacted communities, and industry experts—in the decision-making process to ensure a diverse range of perspectives is considered in ethical dilemmas.\n",
       "\n",
       "- **Adaptive Governance**: Develop a governance model that can adapt over time to changes in technology and societal norms. This would allow the framework to evolve and refine how principles are balanced.\n",
       "\n",
       "- **Impact Assessments**: Regularly conduct ethical impact assessments to evaluate the implications of AI decisions and implementations to help identify potential conflicts and adjust practices accordingly.\n",
       "\n",
       "- **Robust Oversight Mechanisms**: Establish an independent oversight body that can review AI deployments and ensure compliance with ethical standards, providing checks and balances against misuse or unintentional harm.\n",
       "\n",
       "Overall, an ethical framework for AI should be dynamic, rotating around ongoing discourse and adaptation to societal needs while fostering innovation responsibly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## **Competitor:** claude-3-7-sonnet-latest\n",
       "\n",
       "# Ethical Framework for AI: Balancing Innovation and Society\n",
       "\n",
       "If designing such a framework, I would prioritize these core principles:\n",
       "\n",
       "## Key Principles\n",
       "- **Human welfare and dignity**: AI systems should enhance human wellbeing while respecting autonomy\n",
       "- **Fairness and non-discrimination**: Systems must operate equitably across different populations\n",
       "- **Transparency and explainability**: Decision-making processes should be understandable to those affected\n",
       "- **Accountability**: Clear responsibility structures for AI outcomes\n",
       "- **Safety and robustness**: Systems should be reliable and resilient against misuse\n",
       "- **Privacy**: Protection of personal data and information boundaries\n",
       "\n",
       "## Addressing Conflicts\n",
       "\n",
       "When principles clash, I would implement:\n",
       "\n",
       "1. **Deliberative processes**: Multi-stakeholder forums including affected communities\n",
       "2. **Contextual prioritization**: Recognizing that different domains may require different balancing\n",
       "3. **Minimum ethical thresholds**: Establishing non-negotiable baselines for each principle\n",
       "4. **Iterative adjustment**: Regularly revisiting the framework as technology and society evolve\n",
       "\n",
       "The hardest tensions often arise between innovation and protection. I'd advocate for a \"responsible innovation\" approach where advancement continues but with appropriate safeguards and inclusive participation in governance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## **Competitor:** gemini-2.0-flash\n",
       "\n",
       "Okay, designing an ethical framework for AI that balances innovation with societal impact is a complex challenge. Here's how I'd approach it, prioritizing key principles and outlining how to address potential conflicts:\n",
       "\n",
       "**I. Core Principles:**\n",
       "\n",
       "1.  **Beneficence (Do Good) & Non-Maleficence (Do No Harm):**\n",
       "    *   **Definition:** AI systems should be designed and used to benefit humanity, improving quality of life, addressing societal challenges, and minimizing harm. This encompasses physical, psychological, economic, and social well-being.\n",
       "    *   **Implementation:**\n",
       "        *   **Impact Assessments:**  Mandatory ethical impact assessments prior to deployment, analyzing potential benefits and harms across diverse stakeholder groups.\n",
       "        *   **Safety-by-Design:**  Incorporating safety mechanisms and fail-safe protocols into the AI system's architecture.\n",
       "        *   **Human Oversight:**  Maintaining human control and oversight, especially in high-stakes decisions (e.g., healthcare, criminal justice).\n",
       "        *   **Monitoring and Mitigation:** Continuous monitoring of AI system performance to identify and mitigate any unforeseen negative consequences.\n",
       "    *   **Metrics:** Track positive impacts like increased efficiency in resource allocation, improved healthcare outcomes, reduced poverty, as well as negative ones like job displacement, algorithmic bias, and privacy breaches.\n",
       "\n",
       "2.  **Fairness & Justice:**\n",
       "    *   **Definition:** AI systems should be equitable and avoid perpetuating or amplifying existing societal biases. Outcomes should be fair and just for all individuals and groups, regardless of protected characteristics (e.g., race, gender, religion, socioeconomic status).\n",
       "    *   **Implementation:**\n",
       "        *   **Data Audits:** Rigorous auditing of training data to identify and mitigate biases.\n",
       "        *   **Algorithmic Transparency:** Providing transparency into the decision-making processes of AI systems, particularly in areas where fairness is critical.\n",
       "        *   **Bias Detection & Mitigation:** Employing techniques to detect and mitigate algorithmic bias throughout the AI lifecycle (data collection, model training, deployment, and monitoring).\n",
       "        *   **Diverse Development Teams:** Ensuring diverse perspectives are represented in the design and development of AI systems.\n",
       "    *   **Metrics:** Measure fairness across different demographic groups using metrics like disparate impact, equal opportunity, and predictive rate parity. Track and address any disparities identified.\n",
       "\n",
       "3.  **Transparency & Explainability:**\n",
       "    *   **Definition:** The inner workings of AI systems, especially those that make important decisions, should be understandable to relevant stakeholders. Explanations should be provided for how decisions are made, allowing for scrutiny and accountability.\n",
       "    *   **Implementation:**\n",
       "        *   **Explainable AI (XAI) Techniques:** Utilizing XAI methods to provide insights into AI decision-making processes.\n",
       "        *   **Documentation:** Providing clear and accessible documentation about the AI system's design, training data, limitations, and intended use.\n",
       "        *   **Auditing & Review:** Establishing mechanisms for auditing and reviewing AI systems to ensure they are operating as intended and that their decisions are justified.\n",
       "        *   **Right to Explanation:** Granting individuals the right to receive an explanation for decisions made by AI systems that affect them.\n",
       "    *   **Metrics:** Measure the degree to which AI systems are understandable and interpretable, using metrics like explanation accuracy, coverage, and user satisfaction with explanations.\n",
       "\n",
       "4.  **Accountability & Responsibility:**\n",
       "    *   **Definition:** Clear lines of responsibility should be established for the design, development, deployment, and use of AI systems. Individuals and organizations should be held accountable for the consequences of AI systems' actions.\n",
       "    *   **Implementation:**\n",
       "        *   **Defined Roles & Responsibilities:** Clearly defining roles and responsibilities for each stage of the AI lifecycle.\n",
       "        *   **Auditing & Monitoring:** Implementing auditing and monitoring mechanisms to track the performance of AI systems and identify any potential issues.\n",
       "        *   **Remedial Mechanisms:** Establishing mechanisms for redress and compensation in cases where AI systems cause harm.\n",
       "        *   **Ethical Review Boards:** Creating ethical review boards to oversee the development and deployment of AI systems.\n",
       "    *   **Metrics:** Track the effectiveness of accountability mechanisms in preventing harm and ensuring responsible AI development and deployment. Measure the number of incidents involving AI-related harm, the effectiveness of redress mechanisms, and the level of public trust in AI systems.\n",
       "\n",
       "5.  **Privacy & Data Governance:**\n",
       "    *   **Definition:** AI systems should respect individuals' privacy rights and protect their personal data. Data should be collected, used, and stored responsibly and securely.\n",
       "    *   **Implementation:**\n",
       "        *   **Data Minimization:** Collecting only the data that is necessary for the intended purpose.\n",
       "        *   **Data Security:** Implementing robust security measures to protect data from unauthorized access, use, or disclosure.\n",
       "        *   **Privacy-Preserving Technologies:** Employing privacy-preserving technologies (e.g., differential privacy, federated learning) to minimize the risk of data breaches and protect individual privacy.\n",
       "        *   **User Consent & Control:** Obtaining informed consent from individuals before collecting and using their data, and giving them control over their data.\n",
       "    *   **Metrics:** Track the number of data breaches, the level of user control over their data, and the adoption of privacy-preserving technologies.\n",
       "\n",
       "6.  **Sustainability:**\n",
       "    *   **Definition:** AI development and deployment should be environmentally sustainable, minimizing its carbon footprint and resource consumption. This also extends to the long-term social and economic sustainability of AI adoption.\n",
       "    *   **Implementation:**\n",
       "        *   **Energy Efficiency:** Optimizing AI algorithms and infrastructure for energy efficiency.\n",
       "        *   **Responsible Resource Use:**  Minimizing the use of scarce resources (e.g., rare earth minerals) in AI development.\n",
       "        *   **Life Cycle Assessment:** Conducting life cycle assessments of AI systems to assess their environmental impact.\n",
       "        *   **Promoting Green AI:** Fostering research and development in green AI technologies.\n",
       "    *   **Metrics:** Track the energy consumption, resource usage, and carbon footprint of AI systems. Measure the adoption of green AI technologies and practices.\n",
       "\n",
       "**II. Addressing Potential Conflicts Between Principles:**\n",
       "\n",
       "Conflicts between these principles are inevitable. Here's how to navigate them:\n",
       "\n",
       "1.  **Prioritization Framework:**\n",
       "    *   **Context-Specific Prioritization:**  Recognize that the relative importance of different principles will vary depending on the specific context and application of the AI system. For example, in medical diagnosis, beneficence and non-maleficence might take precedence over transparency in certain emergency situations.\n",
       "    *   **Deliberative Processes:**  Establish clear processes for deliberating about and resolving conflicts between ethical principles, involving diverse stakeholders (e.g., ethicists, developers, users, policymakers).\n",
       "    *   **Hierarchical Structure (with Caution):**  While not always ideal, a hierarchical structure *might* be necessary in certain narrow cases.  For instance, laws protecting fundamental human rights *might* supersede other considerations. However, any hierarchical structure should be carefully justified and subject to ongoing review.\n",
       "\n",
       "2.  **Trade-off Analysis:**\n",
       "    *   **Transparency about Trade-offs:**  Acknowledge and communicate openly about the trade-offs that are being made when prioritizing one principle over another.\n",
       "    *   **Minimizing Harm:**  When making trade-offs, prioritize minimizing harm to individuals and society.\n",
       "    *   **Seeking Synergies:**  Explore opportunities to achieve multiple ethical goals simultaneously.  For example, using privacy-preserving techniques can also enhance data security.\n",
       "\n",
       "3.  **Robust Governance & Oversight:**\n",
       "    *   **Multi-Stakeholder Governance:**  Establish governance structures that involve diverse stakeholders in the oversight of AI development and deployment.\n",
       "    *   **Independent Audits:**  Conduct regular independent audits of AI systems to assess their compliance with ethical principles.\n",
       "    *   **Regulatory Frameworks:**  Develop clear regulatory frameworks that provide guidance on the ethical development and use of AI.\n",
       "\n",
       "4.  **Continuous Learning & Adaptation:**\n",
       "    *   **Iterative Ethical Review:**  Regularly review and update the ethical framework to reflect new developments in AI and evolving societal values.\n",
       "    *   **Feedback Mechanisms:**  Establish mechanisms for gathering feedback from users and the public about the ethical implications of AI systems.\n",
       "    *   **Research & Development:**  Invest in research and development on ethical AI to address emerging challenges and opportunities.\n",
       "\n",
       "**III. Example Scenario: Facial Recognition Technology:**\n",
       "\n",
       "*   **Principle Conflict:**  Innovation in facial recognition can improve security (beneficence), but also threaten privacy and potentially lead to biased surveillance (non-maleficence, fairness).\n",
       "*   **Resolution:**\n",
       "    *   **Contextual Limitations:**  Restrict the use of facial recognition to specific, high-risk scenarios (e.g., airport security, criminal investigations) and prohibit its use in public spaces for general surveillance.\n",
       "    *   **Transparency & Accountability:**  Require clear signage indicating when facial recognition is being used, and establish mechanisms for oversight and accountability.\n",
       "    *   **Bias Mitigation:**  Invest in research and development to mitigate bias in facial recognition algorithms.\n",
       "    *   **Data Security:**  Implement strong data security measures to protect data from unauthorized access and misuse.\n",
       "    *   **Human Review:** Require human review of facial recognition matches before any action is taken.\n",
       "\n",
       "**IV. Key Considerations for Success:**\n",
       "\n",
       "*   **International Cooperation:**  Ethical AI development requires international cooperation to ensure that ethical principles are consistent across borders.\n",
       "*   **Education & Awareness:**  Promote education and awareness about the ethical implications of AI among developers, users, and the public.\n",
       "*   **Incentives:**  Provide incentives for organizations to develop and deploy AI systems ethically.\n",
       "\n",
       "By adopting these principles and implementing these strategies, we can create an ethical framework for AI that promotes innovation while safeguarding human values and ensuring that AI benefits all of humanity. It's an ongoing process that requires constant vigilance, adaptation, and a commitment to ethical principles.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## **Competitor:** llama3.2\n",
       "\n",
       "Designing an ethical framework for artificial intelligence (AI) that balances innovation with societal impact requires careful consideration of several key principles. Here are some principles I would prioritize, along with suggestions for addressing potential conflicts between them:\n",
       "\n",
       "1. **Transparency**: Ensure that AI systems are transparent in their decision-making processes, allowing users and stakeholders to understand how they arrive at conclusions.\n",
       "\t* Addressing conflict: When deciding on transparency levels, consider the level of understanding required by different stakeholders (e.g., general public vs. experts).\n",
       "\n",
       "2. **Accountability**: Hold developers, deployers, and users accountable for AI system development, deployment, and performance, ensuring that all parties are responsible for negative consequences.\n",
       "\t* Addressing conflict: Establish clear lines of accountability, such as defining roles and responsibilities in AI-related decision-making.\n",
       "\n",
       "3. **Fairness**: Ensure that AI systems do not perpetuate or exacerbate existing societal biases, discrimination, or inequities.\n",
       "\t* Addressing conflict: Implement robust auditing mechanisms to detect bias, monitor demographics' impact on decisions made by the system\n",
       "\n",
       "4. **Privacy**: Protect users' privacy and security rights by preserving personal data and protecting against unauthorized access or misuse.\n",
       "\t* Addressing conflict: Utilize cryptography to safeguard user information in AI-driven decision-making.\n",
       "\n",
       "5. **Purpose Limitation**: Ensure that AI systems operate within established ethical limits, avoiding actions which could cause significant harm or negative social impact.\n",
       "\t* Addressing conflict: Establish a set of specific guidelines and regulations that outline the maximum extent in which AI should be utilized for different scenarios.\n",
       "\n",
       "6. **Human Wellbeing**: Prioritize human well-being and consider potential consequences on people's health, happiness, safety, and other aspects when developing AI-driven solutions.\n",
       "\t* Addressing conflict: Evaluate systems using multiple metrics: one must balance outcomes with the side effects felt by individuals through direct or indirect means \n",
       "\n",
       "7. **Autonomy**: Recognize the autonomy of humans in areas where AI cannot improve decisions, taking care that both are valued equally, and no particular person receives a 'preferential advantage'.\n",
       "\n",
       "8.  Resilience and Safety: Ensure that AI systems can evolve to changing scenarios and conditions effectively without undermining basic human values.\n",
       "\t* Addressing conflict: Continuously test and train in controlled experiments, incorporating knowledge generated from those tests into safety testing protocols"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## **Competitor:** deepseek-chat\n",
       "\n",
       "Designing an ethical framework for AI that balances innovation with societal impact requires prioritizing principles that ensure responsible development while fostering progress. Below are the key principles I would prioritize and strategies to address conflicts between them:\n",
       "\n",
       "### **Key Principles:**\n",
       "1. **Transparency & Explainability**  \n",
       "   - AI systems should be understandable to stakeholders (users, developers, regulators).  \n",
       "   - Decisions made by AI should be explainable, especially in high-stakes domains (healthcare, criminal justice).  \n",
       "\n",
       "2. **Fairness & Non-Discrimination**  \n",
       "   - AI should avoid biases in data and algorithms that could harm marginalized groups.  \n",
       "   - Regular audits should assess fairness across demographic groups.  \n",
       "\n",
       "3. **Accountability & Responsibility**  \n",
       "   - Clear lines of responsibility for AI outcomes (developers, deployers, regulators).  \n",
       "   - Mechanisms for redress if AI causes harm.  \n",
       "\n",
       "4. **Privacy & Data Protection**  \n",
       "   - Minimize data collection and ensure robust security.  \n",
       "   - Comply with regulations like GDPR and ensure user consent.  \n",
       "\n",
       "5. **Safety & Robustness**  \n",
       "   - AI systems must be reliable, secure, and resilient against misuse.  \n",
       "   - Rigorous testing before deployment, especially in critical applications.  \n",
       "\n",
       "6. **Human Autonomy & Control**  \n",
       "   - AI should augment, not replace, human decision-making in sensitive areas.  \n",
       "   - Users should have meaningful oversight and opt-out options.  \n",
       "\n",
       "7. **Societal Benefit & Sustainability**  \n",
       "   - AI should contribute to public good (e.g., healthcare, climate solutions).  \n",
       "   - Avoid applications that exacerbate inequality or environmental harm.  \n",
       "\n",
       "8. **Innovation & Openness**  \n",
       "   - Encourage research and collaboration while mitigating risks.  \n",
       "   - Balance proprietary interests with open-source contributions for public benefit.  \n",
       "\n",
       "### **Addressing Conflicts Between Principles:**  \n",
       "Conflicts may arise—e.g., **privacy vs. innovation** (data restrictions may limit AI training) or **autonomy vs. safety** (strict controls may stifle creativity). Strategies to resolve tensions:  \n",
       "\n",
       "- **Risk-Benefit Analysis:** Weigh societal harms against potential gains (e.g., facial recognition for security vs. privacy risks).  \n",
       "- **Stakeholder Engagement:** Involve diverse voices (technologists, ethicists, policymakers, affected communities) in decision-making.  \n",
       "- **Tiered Governance:** Stricter rules for high-risk applications (medical AI) vs. lighter oversight for low-risk uses (recommendation systems).  \n",
       "- **Adaptive Policies:** Update guidelines as technology evolves, balancing flexibility with safeguards.  \n",
       "- **Ethical Trade-off Frameworks:** Use decision matrices to evaluate trade-offs (e.g., prioritizing fairness over speed in hiring algorithms).  \n",
       "\n",
       "### **Conclusion:**  \n",
       "A robust ethical AI framework must be **dynamic, inclusive, and context-aware**, ensuring innovation thrives while minimizing harm. By embedding these principles in governance structures and fostering ongoing dialogue, we can navigate conflicts responsibly.  \n",
       "\n",
       "Would you emphasize any additional principles or conflict-resolution approaches?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    display(Markdown(f\"## **Competitor:** {competitor}\\n\\n{answer}\"))\n",
    "    display(Markdown(f\"\\n---\\n---\\n\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n---\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "---\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) is a complex task that requires careful consideration of various principles to balance innovation with societal impact. Here are some key principles I would prioritize:\n",
      "\n",
      "1. **Transparency**: AI systems should be designed to be transparent in their decision-making processes. This includes providing clear explanations of how algorithms work and allowing stakeholders to understand how decisions are made.\n",
      "\n",
      "2. **Accountability**: There should be clear lines of responsibility for AI systems and their outcomes. Developers, organizations, and users must be accountable for the decisions made by AI and must establish mechanisms for redress in case of harm.\n",
      "\n",
      "3. **Fairness and Non-Discrimination**: AI applications should avoid biases and discriminatory practices. This includes ensuring that data used for training does not reinforce existing social inequalities and that outcomes are fair across different demographics.\n",
      "\n",
      "4. **Privacy and Data Protection**: AI systems must respect individuals’ privacy and safeguard personal data. This requires adherence to data protection regulations and the establishment of ethical data handling practices.\n",
      "\n",
      "5. **Beneficence**: AI should be developed and deployed in ways that promote the well-being of individuals and society as a whole. This means prioritizing applications that contribute positively to societal challenges, such as healthcare, education, and environmental sustainability.\n",
      "\n",
      "6. **Inclusivity and Accessibility**: AI technologies should be designed to be accessible to all and consider diverse user perspectives. This involves actively involving different communities in the design process and ensuring that technologies do not marginalize certain groups.\n",
      "\n",
      "7. **Sustainability**: The development of AI should consider the environmental impact, aiming for energy-efficient solutions and minimizing carbon footprints associated with training complex models.\n",
      "\n",
      "8. **Human-Centric Design**: AI should augment human capabilities and enhance human agency, rather than replacing humans or diminishing their roles. Keeping humans in the loop ensures decisions made by AI align with human values and ethics.\n",
      "\n",
      "### Addressing Potential Conflicts:\n",
      "Conflicts can arise between these principles. For instance, a push for transparency may conflict with the need for privacy, as releasing algorithms or data might expose sensitive information. To address such conflicts, the following strategies could be employed:\n",
      "\n",
      "- **Contextual Guidelines**: Establish context-specific guidelines to determine when and how principles should be prioritized, based on the use case and potential impact.\n",
      "\n",
      "- **Stakeholder Engagement**: Involve stakeholders—including ethicists, impacted communities, and industry experts—in the decision-making process to ensure a diverse range of perspectives is considered in ethical dilemmas.\n",
      "\n",
      "- **Adaptive Governance**: Develop a governance model that can adapt over time to changes in technology and societal norms. This would allow the framework to evolve and refine how principles are balanced.\n",
      "\n",
      "- **Impact Assessments**: Regularly conduct ethical impact assessments to evaluate the implications of AI decisions and implementations to help identify potential conflicts and adjust practices accordingly.\n",
      "\n",
      "- **Robust Oversight Mechanisms**: Establish an independent oversight body that can review AI deployments and ensure compliance with ethical standards, providing checks and balances against misuse or unintentional harm.\n",
      "\n",
      "Overall, an ethical framework for AI should be dynamic, rotating around ongoing discourse and adaptation to societal needs while fostering innovation responsibly.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "---\n",
      "\n",
      "# Ethical Framework for AI: Balancing Innovation and Society\n",
      "\n",
      "If designing such a framework, I would prioritize these core principles:\n",
      "\n",
      "## Key Principles\n",
      "- **Human welfare and dignity**: AI systems should enhance human wellbeing while respecting autonomy\n",
      "- **Fairness and non-discrimination**: Systems must operate equitably across different populations\n",
      "- **Transparency and explainability**: Decision-making processes should be understandable to those affected\n",
      "- **Accountability**: Clear responsibility structures for AI outcomes\n",
      "- **Safety and robustness**: Systems should be reliable and resilient against misuse\n",
      "- **Privacy**: Protection of personal data and information boundaries\n",
      "\n",
      "## Addressing Conflicts\n",
      "\n",
      "When principles clash, I would implement:\n",
      "\n",
      "1. **Deliberative processes**: Multi-stakeholder forums including affected communities\n",
      "2. **Contextual prioritization**: Recognizing that different domains may require different balancing\n",
      "3. **Minimum ethical thresholds**: Establishing non-negotiable baselines for each principle\n",
      "4. **Iterative adjustment**: Regularly revisiting the framework as technology and society evolve\n",
      "\n",
      "The hardest tensions often arise between innovation and protection. I'd advocate for a \"responsible innovation\" approach where advancement continues but with appropriate safeguards and inclusive participation in governance.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "---\n",
      "\n",
      "Okay, designing an ethical framework for AI that balances innovation with societal impact is a complex challenge. Here's how I'd approach it, prioritizing key principles and outlining how to address potential conflicts:\n",
      "\n",
      "**I. Core Principles:**\n",
      "\n",
      "1.  **Beneficence (Do Good) & Non-Maleficence (Do No Harm):**\n",
      "    *   **Definition:** AI systems should be designed and used to benefit humanity, improving quality of life, addressing societal challenges, and minimizing harm. This encompasses physical, psychological, economic, and social well-being.\n",
      "    *   **Implementation:**\n",
      "        *   **Impact Assessments:**  Mandatory ethical impact assessments prior to deployment, analyzing potential benefits and harms across diverse stakeholder groups.\n",
      "        *   **Safety-by-Design:**  Incorporating safety mechanisms and fail-safe protocols into the AI system's architecture.\n",
      "        *   **Human Oversight:**  Maintaining human control and oversight, especially in high-stakes decisions (e.g., healthcare, criminal justice).\n",
      "        *   **Monitoring and Mitigation:** Continuous monitoring of AI system performance to identify and mitigate any unforeseen negative consequences.\n",
      "    *   **Metrics:** Track positive impacts like increased efficiency in resource allocation, improved healthcare outcomes, reduced poverty, as well as negative ones like job displacement, algorithmic bias, and privacy breaches.\n",
      "\n",
      "2.  **Fairness & Justice:**\n",
      "    *   **Definition:** AI systems should be equitable and avoid perpetuating or amplifying existing societal biases. Outcomes should be fair and just for all individuals and groups, regardless of protected characteristics (e.g., race, gender, religion, socioeconomic status).\n",
      "    *   **Implementation:**\n",
      "        *   **Data Audits:** Rigorous auditing of training data to identify and mitigate biases.\n",
      "        *   **Algorithmic Transparency:** Providing transparency into the decision-making processes of AI systems, particularly in areas where fairness is critical.\n",
      "        *   **Bias Detection & Mitigation:** Employing techniques to detect and mitigate algorithmic bias throughout the AI lifecycle (data collection, model training, deployment, and monitoring).\n",
      "        *   **Diverse Development Teams:** Ensuring diverse perspectives are represented in the design and development of AI systems.\n",
      "    *   **Metrics:** Measure fairness across different demographic groups using metrics like disparate impact, equal opportunity, and predictive rate parity. Track and address any disparities identified.\n",
      "\n",
      "3.  **Transparency & Explainability:**\n",
      "    *   **Definition:** The inner workings of AI systems, especially those that make important decisions, should be understandable to relevant stakeholders. Explanations should be provided for how decisions are made, allowing for scrutiny and accountability.\n",
      "    *   **Implementation:**\n",
      "        *   **Explainable AI (XAI) Techniques:** Utilizing XAI methods to provide insights into AI decision-making processes.\n",
      "        *   **Documentation:** Providing clear and accessible documentation about the AI system's design, training data, limitations, and intended use.\n",
      "        *   **Auditing & Review:** Establishing mechanisms for auditing and reviewing AI systems to ensure they are operating as intended and that their decisions are justified.\n",
      "        *   **Right to Explanation:** Granting individuals the right to receive an explanation for decisions made by AI systems that affect them.\n",
      "    *   **Metrics:** Measure the degree to which AI systems are understandable and interpretable, using metrics like explanation accuracy, coverage, and user satisfaction with explanations.\n",
      "\n",
      "4.  **Accountability & Responsibility:**\n",
      "    *   **Definition:** Clear lines of responsibility should be established for the design, development, deployment, and use of AI systems. Individuals and organizations should be held accountable for the consequences of AI systems' actions.\n",
      "    *   **Implementation:**\n",
      "        *   **Defined Roles & Responsibilities:** Clearly defining roles and responsibilities for each stage of the AI lifecycle.\n",
      "        *   **Auditing & Monitoring:** Implementing auditing and monitoring mechanisms to track the performance of AI systems and identify any potential issues.\n",
      "        *   **Remedial Mechanisms:** Establishing mechanisms for redress and compensation in cases where AI systems cause harm.\n",
      "        *   **Ethical Review Boards:** Creating ethical review boards to oversee the development and deployment of AI systems.\n",
      "    *   **Metrics:** Track the effectiveness of accountability mechanisms in preventing harm and ensuring responsible AI development and deployment. Measure the number of incidents involving AI-related harm, the effectiveness of redress mechanisms, and the level of public trust in AI systems.\n",
      "\n",
      "5.  **Privacy & Data Governance:**\n",
      "    *   **Definition:** AI systems should respect individuals' privacy rights and protect their personal data. Data should be collected, used, and stored responsibly and securely.\n",
      "    *   **Implementation:**\n",
      "        *   **Data Minimization:** Collecting only the data that is necessary for the intended purpose.\n",
      "        *   **Data Security:** Implementing robust security measures to protect data from unauthorized access, use, or disclosure.\n",
      "        *   **Privacy-Preserving Technologies:** Employing privacy-preserving technologies (e.g., differential privacy, federated learning) to minimize the risk of data breaches and protect individual privacy.\n",
      "        *   **User Consent & Control:** Obtaining informed consent from individuals before collecting and using their data, and giving them control over their data.\n",
      "    *   **Metrics:** Track the number of data breaches, the level of user control over their data, and the adoption of privacy-preserving technologies.\n",
      "\n",
      "6.  **Sustainability:**\n",
      "    *   **Definition:** AI development and deployment should be environmentally sustainable, minimizing its carbon footprint and resource consumption. This also extends to the long-term social and economic sustainability of AI adoption.\n",
      "    *   **Implementation:**\n",
      "        *   **Energy Efficiency:** Optimizing AI algorithms and infrastructure for energy efficiency.\n",
      "        *   **Responsible Resource Use:**  Minimizing the use of scarce resources (e.g., rare earth minerals) in AI development.\n",
      "        *   **Life Cycle Assessment:** Conducting life cycle assessments of AI systems to assess their environmental impact.\n",
      "        *   **Promoting Green AI:** Fostering research and development in green AI technologies.\n",
      "    *   **Metrics:** Track the energy consumption, resource usage, and carbon footprint of AI systems. Measure the adoption of green AI technologies and practices.\n",
      "\n",
      "**II. Addressing Potential Conflicts Between Principles:**\n",
      "\n",
      "Conflicts between these principles are inevitable. Here's how to navigate them:\n",
      "\n",
      "1.  **Prioritization Framework:**\n",
      "    *   **Context-Specific Prioritization:**  Recognize that the relative importance of different principles will vary depending on the specific context and application of the AI system. For example, in medical diagnosis, beneficence and non-maleficence might take precedence over transparency in certain emergency situations.\n",
      "    *   **Deliberative Processes:**  Establish clear processes for deliberating about and resolving conflicts between ethical principles, involving diverse stakeholders (e.g., ethicists, developers, users, policymakers).\n",
      "    *   **Hierarchical Structure (with Caution):**  While not always ideal, a hierarchical structure *might* be necessary in certain narrow cases.  For instance, laws protecting fundamental human rights *might* supersede other considerations. However, any hierarchical structure should be carefully justified and subject to ongoing review.\n",
      "\n",
      "2.  **Trade-off Analysis:**\n",
      "    *   **Transparency about Trade-offs:**  Acknowledge and communicate openly about the trade-offs that are being made when prioritizing one principle over another.\n",
      "    *   **Minimizing Harm:**  When making trade-offs, prioritize minimizing harm to individuals and society.\n",
      "    *   **Seeking Synergies:**  Explore opportunities to achieve multiple ethical goals simultaneously.  For example, using privacy-preserving techniques can also enhance data security.\n",
      "\n",
      "3.  **Robust Governance & Oversight:**\n",
      "    *   **Multi-Stakeholder Governance:**  Establish governance structures that involve diverse stakeholders in the oversight of AI development and deployment.\n",
      "    *   **Independent Audits:**  Conduct regular independent audits of AI systems to assess their compliance with ethical principles.\n",
      "    *   **Regulatory Frameworks:**  Develop clear regulatory frameworks that provide guidance on the ethical development and use of AI.\n",
      "\n",
      "4.  **Continuous Learning & Adaptation:**\n",
      "    *   **Iterative Ethical Review:**  Regularly review and update the ethical framework to reflect new developments in AI and evolving societal values.\n",
      "    *   **Feedback Mechanisms:**  Establish mechanisms for gathering feedback from users and the public about the ethical implications of AI systems.\n",
      "    *   **Research & Development:**  Invest in research and development on ethical AI to address emerging challenges and opportunities.\n",
      "\n",
      "**III. Example Scenario: Facial Recognition Technology:**\n",
      "\n",
      "*   **Principle Conflict:**  Innovation in facial recognition can improve security (beneficence), but also threaten privacy and potentially lead to biased surveillance (non-maleficence, fairness).\n",
      "*   **Resolution:**\n",
      "    *   **Contextual Limitations:**  Restrict the use of facial recognition to specific, high-risk scenarios (e.g., airport security, criminal investigations) and prohibit its use in public spaces for general surveillance.\n",
      "    *   **Transparency & Accountability:**  Require clear signage indicating when facial recognition is being used, and establish mechanisms for oversight and accountability.\n",
      "    *   **Bias Mitigation:**  Invest in research and development to mitigate bias in facial recognition algorithms.\n",
      "    *   **Data Security:**  Implement strong data security measures to protect data from unauthorized access and misuse.\n",
      "    *   **Human Review:** Require human review of facial recognition matches before any action is taken.\n",
      "\n",
      "**IV. Key Considerations for Success:**\n",
      "\n",
      "*   **International Cooperation:**  Ethical AI development requires international cooperation to ensure that ethical principles are consistent across borders.\n",
      "*   **Education & Awareness:**  Promote education and awareness about the ethical implications of AI among developers, users, and the public.\n",
      "*   **Incentives:**  Provide incentives for organizations to develop and deploy AI systems ethically.\n",
      "\n",
      "By adopting these principles and implementing these strategies, we can create an ethical framework for AI that promotes innovation while safeguarding human values and ensuring that AI benefits all of humanity. It's an ongoing process that requires constant vigilance, adaptation, and a commitment to ethical principles.\n",
      "\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "---\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that balances innovation with societal impact requires careful consideration of several key principles. Here are some principles I would prioritize, along with suggestions for addressing potential conflicts between them:\n",
      "\n",
      "1. **Transparency**: Ensure that AI systems are transparent in their decision-making processes, allowing users and stakeholders to understand how they arrive at conclusions.\n",
      "\t* Addressing conflict: When deciding on transparency levels, consider the level of understanding required by different stakeholders (e.g., general public vs. experts).\n",
      "\n",
      "2. **Accountability**: Hold developers, deployers, and users accountable for AI system development, deployment, and performance, ensuring that all parties are responsible for negative consequences.\n",
      "\t* Addressing conflict: Establish clear lines of accountability, such as defining roles and responsibilities in AI-related decision-making.\n",
      "\n",
      "3. **Fairness**: Ensure that AI systems do not perpetuate or exacerbate existing societal biases, discrimination, or inequities.\n",
      "\t* Addressing conflict: Implement robust auditing mechanisms to detect bias, monitor demographics' impact on decisions made by the system\n",
      "\n",
      "4. **Privacy**: Protect users' privacy and security rights by preserving personal data and protecting against unauthorized access or misuse.\n",
      "\t* Addressing conflict: Utilize cryptography to safeguard user information in AI-driven decision-making.\n",
      "\n",
      "5. **Purpose Limitation**: Ensure that AI systems operate within established ethical limits, avoiding actions which could cause significant harm or negative social impact.\n",
      "\t* Addressing conflict: Establish a set of specific guidelines and regulations that outline the maximum extent in which AI should be utilized for different scenarios.\n",
      "\n",
      "6. **Human Wellbeing**: Prioritize human well-being and consider potential consequences on people's health, happiness, safety, and other aspects when developing AI-driven solutions.\n",
      "\t* Addressing conflict: Evaluate systems using multiple metrics: one must balance outcomes with the side effects felt by individuals through direct or indirect means \n",
      "\n",
      "7. **Autonomy**: Recognize the autonomy of humans in areas where AI cannot improve decisions, taking care that both are valued equally, and no particular person receives a 'preferential advantage'.\n",
      "\n",
      "8.  Resilience and Safety: Ensure that AI systems can evolve to changing scenarios and conditions effectively without undermining basic human values.\n",
      "\t* Addressing conflict: Continuously test and train in controlled experiments, incorporating knowledge generated from those tests into safety testing protocols\n",
      "\n",
      "# Response from competitor 5\n",
      "\n",
      "---\n",
      "\n",
      "Designing an ethical framework for AI that balances innovation with societal impact requires prioritizing principles that ensure responsible development while fostering progress. Below are the key principles I would prioritize and strategies to address conflicts between them:\n",
      "\n",
      "### **Key Principles:**\n",
      "1. **Transparency & Explainability**  \n",
      "   - AI systems should be understandable to stakeholders (users, developers, regulators).  \n",
      "   - Decisions made by AI should be explainable, especially in high-stakes domains (healthcare, criminal justice).  \n",
      "\n",
      "2. **Fairness & Non-Discrimination**  \n",
      "   - AI should avoid biases in data and algorithms that could harm marginalized groups.  \n",
      "   - Regular audits should assess fairness across demographic groups.  \n",
      "\n",
      "3. **Accountability & Responsibility**  \n",
      "   - Clear lines of responsibility for AI outcomes (developers, deployers, regulators).  \n",
      "   - Mechanisms for redress if AI causes harm.  \n",
      "\n",
      "4. **Privacy & Data Protection**  \n",
      "   - Minimize data collection and ensure robust security.  \n",
      "   - Comply with regulations like GDPR and ensure user consent.  \n",
      "\n",
      "5. **Safety & Robustness**  \n",
      "   - AI systems must be reliable, secure, and resilient against misuse.  \n",
      "   - Rigorous testing before deployment, especially in critical applications.  \n",
      "\n",
      "6. **Human Autonomy & Control**  \n",
      "   - AI should augment, not replace, human decision-making in sensitive areas.  \n",
      "   - Users should have meaningful oversight and opt-out options.  \n",
      "\n",
      "7. **Societal Benefit & Sustainability**  \n",
      "   - AI should contribute to public good (e.g., healthcare, climate solutions).  \n",
      "   - Avoid applications that exacerbate inequality or environmental harm.  \n",
      "\n",
      "8. **Innovation & Openness**  \n",
      "   - Encourage research and collaboration while mitigating risks.  \n",
      "   - Balance proprietary interests with open-source contributions for public benefit.  \n",
      "\n",
      "### **Addressing Conflicts Between Principles:**  \n",
      "Conflicts may arise—e.g., **privacy vs. innovation** (data restrictions may limit AI training) or **autonomy vs. safety** (strict controls may stifle creativity). Strategies to resolve tensions:  \n",
      "\n",
      "- **Risk-Benefit Analysis:** Weigh societal harms against potential gains (e.g., facial recognition for security vs. privacy risks).  \n",
      "- **Stakeholder Engagement:** Involve diverse voices (technologists, ethicists, policymakers, affected communities) in decision-making.  \n",
      "- **Tiered Governance:** Stricter rules for high-risk applications (medical AI) vs. lighter oversight for low-risk uses (recommendation systems).  \n",
      "- **Adaptive Policies:** Update guidelines as technology evolves, balancing flexibility with safeguards.  \n",
      "- **Ethical Trade-off Frameworks:** Use decision matrices to evaluate trade-offs (e.g., prioritizing fairness over speed in hiring algorithms).  \n",
      "\n",
      "### **Conclusion:**  \n",
      "A robust ethical AI framework must be **dynamic, inclusive, and context-aware**, ensuring innovation thrives while minimizing harm. By embedding these principles in governance structures and fostering ongoing dialogue, we can navigate conflicts responsibly.  \n",
      "\n",
      "Would you emphasize any additional principles or conflict-resolution approaches?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"\n",
    "You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 5 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "If you were tasked with designing an ethical framework for artificial intelligence that balances innovation with societal impact, what key principles would you prioritize, and how would you address potential conflicts between those principles?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "---\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) is a complex task that requires careful consideration of various principles to balance innovation with societal impact. Here are some key principles I would prioritize:\n",
      "\n",
      "1. **Transparency**: AI systems should be designed to be transparent in their decision-making processes. This includes providing clear explanations of how algorithms work and allowing stakeholders to understand how decisions are made.\n",
      "\n",
      "2. **Accountability**: There should be clear lines of responsibility for AI systems and their outcomes. Developers, organizations, and users must be accountable for the decisions made by AI and must establish mechanisms for redress in case of harm.\n",
      "\n",
      "3. **Fairness and Non-Discrimination**: AI applications should avoid biases and discriminatory practices. This includes ensuring that data used for training does not reinforce existing social inequalities and that outcomes are fair across different demographics.\n",
      "\n",
      "4. **Privacy and Data Protection**: AI systems must respect individuals’ privacy and safeguard personal data. This requires adherence to data protection regulations and the establishment of ethical data handling practices.\n",
      "\n",
      "5. **Beneficence**: AI should be developed and deployed in ways that promote the well-being of individuals and society as a whole. This means prioritizing applications that contribute positively to societal challenges, such as healthcare, education, and environmental sustainability.\n",
      "\n",
      "6. **Inclusivity and Accessibility**: AI technologies should be designed to be accessible to all and consider diverse user perspectives. This involves actively involving different communities in the design process and ensuring that technologies do not marginalize certain groups.\n",
      "\n",
      "7. **Sustainability**: The development of AI should consider the environmental impact, aiming for energy-efficient solutions and minimizing carbon footprints associated with training complex models.\n",
      "\n",
      "8. **Human-Centric Design**: AI should augment human capabilities and enhance human agency, rather than replacing humans or diminishing their roles. Keeping humans in the loop ensures decisions made by AI align with human values and ethics.\n",
      "\n",
      "### Addressing Potential Conflicts:\n",
      "Conflicts can arise between these principles. For instance, a push for transparency may conflict with the need for privacy, as releasing algorithms or data might expose sensitive information. To address such conflicts, the following strategies could be employed:\n",
      "\n",
      "- **Contextual Guidelines**: Establish context-specific guidelines to determine when and how principles should be prioritized, based on the use case and potential impact.\n",
      "\n",
      "- **Stakeholder Engagement**: Involve stakeholders—including ethicists, impacted communities, and industry experts—in the decision-making process to ensure a diverse range of perspectives is considered in ethical dilemmas.\n",
      "\n",
      "- **Adaptive Governance**: Develop a governance model that can adapt over time to changes in technology and societal norms. This would allow the framework to evolve and refine how principles are balanced.\n",
      "\n",
      "- **Impact Assessments**: Regularly conduct ethical impact assessments to evaluate the implications of AI decisions and implementations to help identify potential conflicts and adjust practices accordingly.\n",
      "\n",
      "- **Robust Oversight Mechanisms**: Establish an independent oversight body that can review AI deployments and ensure compliance with ethical standards, providing checks and balances against misuse or unintentional harm.\n",
      "\n",
      "Overall, an ethical framework for AI should be dynamic, rotating around ongoing discourse and adaptation to societal needs while fostering innovation responsibly.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "---\n",
      "\n",
      "# Ethical Framework for AI: Balancing Innovation and Society\n",
      "\n",
      "If designing such a framework, I would prioritize these core principles:\n",
      "\n",
      "## Key Principles\n",
      "- **Human welfare and dignity**: AI systems should enhance human wellbeing while respecting autonomy\n",
      "- **Fairness and non-discrimination**: Systems must operate equitably across different populations\n",
      "- **Transparency and explainability**: Decision-making processes should be understandable to those affected\n",
      "- **Accountability**: Clear responsibility structures for AI outcomes\n",
      "- **Safety and robustness**: Systems should be reliable and resilient against misuse\n",
      "- **Privacy**: Protection of personal data and information boundaries\n",
      "\n",
      "## Addressing Conflicts\n",
      "\n",
      "When principles clash, I would implement:\n",
      "\n",
      "1. **Deliberative processes**: Multi-stakeholder forums including affected communities\n",
      "2. **Contextual prioritization**: Recognizing that different domains may require different balancing\n",
      "3. **Minimum ethical thresholds**: Establishing non-negotiable baselines for each principle\n",
      "4. **Iterative adjustment**: Regularly revisiting the framework as technology and society evolve\n",
      "\n",
      "The hardest tensions often arise between innovation and protection. I'd advocate for a \"responsible innovation\" approach where advancement continues but with appropriate safeguards and inclusive participation in governance.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "---\n",
      "\n",
      "Okay, designing an ethical framework for AI that balances innovation with societal impact is a complex challenge. Here's how I'd approach it, prioritizing key principles and outlining how to address potential conflicts:\n",
      "\n",
      "**I. Core Principles:**\n",
      "\n",
      "1.  **Beneficence (Do Good) & Non-Maleficence (Do No Harm):**\n",
      "    *   **Definition:** AI systems should be designed and used to benefit humanity, improving quality of life, addressing societal challenges, and minimizing harm. This encompasses physical, psychological, economic, and social well-being.\n",
      "    *   **Implementation:**\n",
      "        *   **Impact Assessments:**  Mandatory ethical impact assessments prior to deployment, analyzing potential benefits and harms across diverse stakeholder groups.\n",
      "        *   **Safety-by-Design:**  Incorporating safety mechanisms and fail-safe protocols into the AI system's architecture.\n",
      "        *   **Human Oversight:**  Maintaining human control and oversight, especially in high-stakes decisions (e.g., healthcare, criminal justice).\n",
      "        *   **Monitoring and Mitigation:** Continuous monitoring of AI system performance to identify and mitigate any unforeseen negative consequences.\n",
      "    *   **Metrics:** Track positive impacts like increased efficiency in resource allocation, improved healthcare outcomes, reduced poverty, as well as negative ones like job displacement, algorithmic bias, and privacy breaches.\n",
      "\n",
      "2.  **Fairness & Justice:**\n",
      "    *   **Definition:** AI systems should be equitable and avoid perpetuating or amplifying existing societal biases. Outcomes should be fair and just for all individuals and groups, regardless of protected characteristics (e.g., race, gender, religion, socioeconomic status).\n",
      "    *   **Implementation:**\n",
      "        *   **Data Audits:** Rigorous auditing of training data to identify and mitigate biases.\n",
      "        *   **Algorithmic Transparency:** Providing transparency into the decision-making processes of AI systems, particularly in areas where fairness is critical.\n",
      "        *   **Bias Detection & Mitigation:** Employing techniques to detect and mitigate algorithmic bias throughout the AI lifecycle (data collection, model training, deployment, and monitoring).\n",
      "        *   **Diverse Development Teams:** Ensuring diverse perspectives are represented in the design and development of AI systems.\n",
      "    *   **Metrics:** Measure fairness across different demographic groups using metrics like disparate impact, equal opportunity, and predictive rate parity. Track and address any disparities identified.\n",
      "\n",
      "3.  **Transparency & Explainability:**\n",
      "    *   **Definition:** The inner workings of AI systems, especially those that make important decisions, should be understandable to relevant stakeholders. Explanations should be provided for how decisions are made, allowing for scrutiny and accountability.\n",
      "    *   **Implementation:**\n",
      "        *   **Explainable AI (XAI) Techniques:** Utilizing XAI methods to provide insights into AI decision-making processes.\n",
      "        *   **Documentation:** Providing clear and accessible documentation about the AI system's design, training data, limitations, and intended use.\n",
      "        *   **Auditing & Review:** Establishing mechanisms for auditing and reviewing AI systems to ensure they are operating as intended and that their decisions are justified.\n",
      "        *   **Right to Explanation:** Granting individuals the right to receive an explanation for decisions made by AI systems that affect them.\n",
      "    *   **Metrics:** Measure the degree to which AI systems are understandable and interpretable, using metrics like explanation accuracy, coverage, and user satisfaction with explanations.\n",
      "\n",
      "4.  **Accountability & Responsibility:**\n",
      "    *   **Definition:** Clear lines of responsibility should be established for the design, development, deployment, and use of AI systems. Individuals and organizations should be held accountable for the consequences of AI systems' actions.\n",
      "    *   **Implementation:**\n",
      "        *   **Defined Roles & Responsibilities:** Clearly defining roles and responsibilities for each stage of the AI lifecycle.\n",
      "        *   **Auditing & Monitoring:** Implementing auditing and monitoring mechanisms to track the performance of AI systems and identify any potential issues.\n",
      "        *   **Remedial Mechanisms:** Establishing mechanisms for redress and compensation in cases where AI systems cause harm.\n",
      "        *   **Ethical Review Boards:** Creating ethical review boards to oversee the development and deployment of AI systems.\n",
      "    *   **Metrics:** Track the effectiveness of accountability mechanisms in preventing harm and ensuring responsible AI development and deployment. Measure the number of incidents involving AI-related harm, the effectiveness of redress mechanisms, and the level of public trust in AI systems.\n",
      "\n",
      "5.  **Privacy & Data Governance:**\n",
      "    *   **Definition:** AI systems should respect individuals' privacy rights and protect their personal data. Data should be collected, used, and stored responsibly and securely.\n",
      "    *   **Implementation:**\n",
      "        *   **Data Minimization:** Collecting only the data that is necessary for the intended purpose.\n",
      "        *   **Data Security:** Implementing robust security measures to protect data from unauthorized access, use, or disclosure.\n",
      "        *   **Privacy-Preserving Technologies:** Employing privacy-preserving technologies (e.g., differential privacy, federated learning) to minimize the risk of data breaches and protect individual privacy.\n",
      "        *   **User Consent & Control:** Obtaining informed consent from individuals before collecting and using their data, and giving them control over their data.\n",
      "    *   **Metrics:** Track the number of data breaches, the level of user control over their data, and the adoption of privacy-preserving technologies.\n",
      "\n",
      "6.  **Sustainability:**\n",
      "    *   **Definition:** AI development and deployment should be environmentally sustainable, minimizing its carbon footprint and resource consumption. This also extends to the long-term social and economic sustainability of AI adoption.\n",
      "    *   **Implementation:**\n",
      "        *   **Energy Efficiency:** Optimizing AI algorithms and infrastructure for energy efficiency.\n",
      "        *   **Responsible Resource Use:**  Minimizing the use of scarce resources (e.g., rare earth minerals) in AI development.\n",
      "        *   **Life Cycle Assessment:** Conducting life cycle assessments of AI systems to assess their environmental impact.\n",
      "        *   **Promoting Green AI:** Fostering research and development in green AI technologies.\n",
      "    *   **Metrics:** Track the energy consumption, resource usage, and carbon footprint of AI systems. Measure the adoption of green AI technologies and practices.\n",
      "\n",
      "**II. Addressing Potential Conflicts Between Principles:**\n",
      "\n",
      "Conflicts between these principles are inevitable. Here's how to navigate them:\n",
      "\n",
      "1.  **Prioritization Framework:**\n",
      "    *   **Context-Specific Prioritization:**  Recognize that the relative importance of different principles will vary depending on the specific context and application of the AI system. For example, in medical diagnosis, beneficence and non-maleficence might take precedence over transparency in certain emergency situations.\n",
      "    *   **Deliberative Processes:**  Establish clear processes for deliberating about and resolving conflicts between ethical principles, involving diverse stakeholders (e.g., ethicists, developers, users, policymakers).\n",
      "    *   **Hierarchical Structure (with Caution):**  While not always ideal, a hierarchical structure *might* be necessary in certain narrow cases.  For instance, laws protecting fundamental human rights *might* supersede other considerations. However, any hierarchical structure should be carefully justified and subject to ongoing review.\n",
      "\n",
      "2.  **Trade-off Analysis:**\n",
      "    *   **Transparency about Trade-offs:**  Acknowledge and communicate openly about the trade-offs that are being made when prioritizing one principle over another.\n",
      "    *   **Minimizing Harm:**  When making trade-offs, prioritize minimizing harm to individuals and society.\n",
      "    *   **Seeking Synergies:**  Explore opportunities to achieve multiple ethical goals simultaneously.  For example, using privacy-preserving techniques can also enhance data security.\n",
      "\n",
      "3.  **Robust Governance & Oversight:**\n",
      "    *   **Multi-Stakeholder Governance:**  Establish governance structures that involve diverse stakeholders in the oversight of AI development and deployment.\n",
      "    *   **Independent Audits:**  Conduct regular independent audits of AI systems to assess their compliance with ethical principles.\n",
      "    *   **Regulatory Frameworks:**  Develop clear regulatory frameworks that provide guidance on the ethical development and use of AI.\n",
      "\n",
      "4.  **Continuous Learning & Adaptation:**\n",
      "    *   **Iterative Ethical Review:**  Regularly review and update the ethical framework to reflect new developments in AI and evolving societal values.\n",
      "    *   **Feedback Mechanisms:**  Establish mechanisms for gathering feedback from users and the public about the ethical implications of AI systems.\n",
      "    *   **Research & Development:**  Invest in research and development on ethical AI to address emerging challenges and opportunities.\n",
      "\n",
      "**III. Example Scenario: Facial Recognition Technology:**\n",
      "\n",
      "*   **Principle Conflict:**  Innovation in facial recognition can improve security (beneficence), but also threaten privacy and potentially lead to biased surveillance (non-maleficence, fairness).\n",
      "*   **Resolution:**\n",
      "    *   **Contextual Limitations:**  Restrict the use of facial recognition to specific, high-risk scenarios (e.g., airport security, criminal investigations) and prohibit its use in public spaces for general surveillance.\n",
      "    *   **Transparency & Accountability:**  Require clear signage indicating when facial recognition is being used, and establish mechanisms for oversight and accountability.\n",
      "    *   **Bias Mitigation:**  Invest in research and development to mitigate bias in facial recognition algorithms.\n",
      "    *   **Data Security:**  Implement strong data security measures to protect data from unauthorized access and misuse.\n",
      "    *   **Human Review:** Require human review of facial recognition matches before any action is taken.\n",
      "\n",
      "**IV. Key Considerations for Success:**\n",
      "\n",
      "*   **International Cooperation:**  Ethical AI development requires international cooperation to ensure that ethical principles are consistent across borders.\n",
      "*   **Education & Awareness:**  Promote education and awareness about the ethical implications of AI among developers, users, and the public.\n",
      "*   **Incentives:**  Provide incentives for organizations to develop and deploy AI systems ethically.\n",
      "\n",
      "By adopting these principles and implementing these strategies, we can create an ethical framework for AI that promotes innovation while safeguarding human values and ensuring that AI benefits all of humanity. It's an ongoing process that requires constant vigilance, adaptation, and a commitment to ethical principles.\n",
      "\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "---\n",
      "\n",
      "Designing an ethical framework for artificial intelligence (AI) that balances innovation with societal impact requires careful consideration of several key principles. Here are some principles I would prioritize, along with suggestions for addressing potential conflicts between them:\n",
      "\n",
      "1. **Transparency**: Ensure that AI systems are transparent in their decision-making processes, allowing users and stakeholders to understand how they arrive at conclusions.\n",
      "\t* Addressing conflict: When deciding on transparency levels, consider the level of understanding required by different stakeholders (e.g., general public vs. experts).\n",
      "\n",
      "2. **Accountability**: Hold developers, deployers, and users accountable for AI system development, deployment, and performance, ensuring that all parties are responsible for negative consequences.\n",
      "\t* Addressing conflict: Establish clear lines of accountability, such as defining roles and responsibilities in AI-related decision-making.\n",
      "\n",
      "3. **Fairness**: Ensure that AI systems do not perpetuate or exacerbate existing societal biases, discrimination, or inequities.\n",
      "\t* Addressing conflict: Implement robust auditing mechanisms to detect bias, monitor demographics' impact on decisions made by the system\n",
      "\n",
      "4. **Privacy**: Protect users' privacy and security rights by preserving personal data and protecting against unauthorized access or misuse.\n",
      "\t* Addressing conflict: Utilize cryptography to safeguard user information in AI-driven decision-making.\n",
      "\n",
      "5. **Purpose Limitation**: Ensure that AI systems operate within established ethical limits, avoiding actions which could cause significant harm or negative social impact.\n",
      "\t* Addressing conflict: Establish a set of specific guidelines and regulations that outline the maximum extent in which AI should be utilized for different scenarios.\n",
      "\n",
      "6. **Human Wellbeing**: Prioritize human well-being and consider potential consequences on people's health, happiness, safety, and other aspects when developing AI-driven solutions.\n",
      "\t* Addressing conflict: Evaluate systems using multiple metrics: one must balance outcomes with the side effects felt by individuals through direct or indirect means \n",
      "\n",
      "7. **Autonomy**: Recognize the autonomy of humans in areas where AI cannot improve decisions, taking care that both are valued equally, and no particular person receives a 'preferential advantage'.\n",
      "\n",
      "8.  Resilience and Safety: Ensure that AI systems can evolve to changing scenarios and conditions effectively without undermining basic human values.\n",
      "\t* Addressing conflict: Continuously test and train in controlled experiments, incorporating knowledge generated from those tests into safety testing protocols\n",
      "\n",
      "# Response from competitor 5\n",
      "\n",
      "---\n",
      "\n",
      "Designing an ethical framework for AI that balances innovation with societal impact requires prioritizing principles that ensure responsible development while fostering progress. Below are the key principles I would prioritize and strategies to address conflicts between them:\n",
      "\n",
      "### **Key Principles:**\n",
      "1. **Transparency & Explainability**  \n",
      "   - AI systems should be understandable to stakeholders (users, developers, regulators).  \n",
      "   - Decisions made by AI should be explainable, especially in high-stakes domains (healthcare, criminal justice).  \n",
      "\n",
      "2. **Fairness & Non-Discrimination**  \n",
      "   - AI should avoid biases in data and algorithms that could harm marginalized groups.  \n",
      "   - Regular audits should assess fairness across demographic groups.  \n",
      "\n",
      "3. **Accountability & Responsibility**  \n",
      "   - Clear lines of responsibility for AI outcomes (developers, deployers, regulators).  \n",
      "   - Mechanisms for redress if AI causes harm.  \n",
      "\n",
      "4. **Privacy & Data Protection**  \n",
      "   - Minimize data collection and ensure robust security.  \n",
      "   - Comply with regulations like GDPR and ensure user consent.  \n",
      "\n",
      "5. **Safety & Robustness**  \n",
      "   - AI systems must be reliable, secure, and resilient against misuse.  \n",
      "   - Rigorous testing before deployment, especially in critical applications.  \n",
      "\n",
      "6. **Human Autonomy & Control**  \n",
      "   - AI should augment, not replace, human decision-making in sensitive areas.  \n",
      "   - Users should have meaningful oversight and opt-out options.  \n",
      "\n",
      "7. **Societal Benefit & Sustainability**  \n",
      "   - AI should contribute to public good (e.g., healthcare, climate solutions).  \n",
      "   - Avoid applications that exacerbate inequality or environmental harm.  \n",
      "\n",
      "8. **Innovation & Openness**  \n",
      "   - Encourage research and collaboration while mitigating risks.  \n",
      "   - Balance proprietary interests with open-source contributions for public benefit.  \n",
      "\n",
      "### **Addressing Conflicts Between Principles:**  \n",
      "Conflicts may arise—e.g., **privacy vs. innovation** (data restrictions may limit AI training) or **autonomy vs. safety** (strict controls may stifle creativity). Strategies to resolve tensions:  \n",
      "\n",
      "- **Risk-Benefit Analysis:** Weigh societal harms against potential gains (e.g., facial recognition for security vs. privacy risks).  \n",
      "- **Stakeholder Engagement:** Involve diverse voices (technologists, ethicists, policymakers, affected communities) in decision-making.  \n",
      "- **Tiered Governance:** Stricter rules for high-risk applications (medical AI) vs. lighter oversight for low-risk uses (recommendation systems).  \n",
      "- **Adaptive Policies:** Update guidelines as technology evolves, balancing flexibility with safeguards.  \n",
      "- **Ethical Trade-off Frameworks:** Use decision matrices to evaluate trade-offs (e.g., prioritizing fairness over speed in hiring algorithms).  \n",
      "\n",
      "### **Conclusion:**  \n",
      "A robust ethical AI framework must be **dynamic, inclusive, and context-aware**, ensuring innovation thrives while minimizing harm. By embedding these principles in governance structures and fostering ongoing dialogue, we can navigate conflicts responsibly.  \n",
      "\n",
      "Would you emphasize any additional principles or conflict-resolution approaches?\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"results\": [\"3\", \"5\", \"1\", \"2\", \"4\"]}'\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: deepseek-chat\n",
      "Rank 3: gpt-4o-mini\n",
      "Rank 4: claude-3-7-sonnet-latest\n",
      "Rank 5: llama3.2\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
